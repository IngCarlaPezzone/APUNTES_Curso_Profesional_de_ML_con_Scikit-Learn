{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a77d27ea-aea0-43d2-bef5-a7c540edc268",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/IngCarlaPezzone/APUNTES_Curso_Profesional_de_ML_con_Scikit-Learn/blob/main/NotasClases.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bdee0-c6ee-4db6-aefa-67b669d0c167",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Apuntes del Curso Profesional de Machine Learning con Scikit-Learn de Platzi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151eddf9-032a-4e9d-8f73-5adc029b69e0",
   "metadata": {},
   "source": [
    "En este curso se explica cómo se aplican con modelos de Machine Learning a lo largo del flujo de trabajo de Machine Learning: Representación - Evaluación - Optimización\n",
    "\n",
    "Usa distintos conjuntos de datos sencillos para explorar los datos, aplicar modelos simples para luego empezar a aplicar técnicas avanzadas es selección de features, regularización, métodos de ensamble, validación, optimización y mas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bd60b7-1b8f-4e79-92ca-7f251995ee8d",
   "metadata": {},
   "source": [
    "## Configuraciones previas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2cd495c-3123-46e2-9502-5496281088ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.4\n"
     ]
    }
   ],
   "source": [
    "#Conocer la versión de python\n",
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36cbc0b7-dc2b-4af8-978d-ec791506b518",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Marco\\.conda\\envs\\mlenv\n",
      "\n",
      "  added / updated specs:\n",
      "    - scikit-learn\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.01.10 |       haa95532_0         158 KB  anaconda\n",
      "    certifi-2022.12.7          |  py310haa95532_0         153 KB  anaconda\n",
      "    joblib-1.1.1               |  py310haa95532_0         414 KB  anaconda\n",
      "    openssl-1.1.1s             |       h2bbff1b_0         5.8 MB  anaconda\n",
      "    scikit-learn-1.2.0         |  py310hd77b12b_1         7.7 MB  anaconda\n",
      "    threadpoolctl-2.2.0        |     pyh0d69192_0          16 KB  anaconda\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        14.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  joblib             anaconda/win-64::joblib-1.1.1-py310haa95532_0 None\n",
      "  scikit-learn       anaconda/win-64::scikit-learn-1.2.0-py310hd77b12b_1 None\n",
      "  threadpoolctl      anaconda/noarch::threadpoolctl-2.2.0-pyh0d69192_0 None\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    conda-forge::ca-certificates-2022.6.1~ --> anaconda::ca-certificates-2023.01.10-haa95532_0 None\n",
      "  certifi            conda-forge/noarch::certifi-2022.6.15~ --> anaconda/win-64::certifi-2022.12.7-py310haa95532_0 None\n",
      "  openssl            conda-forge::openssl-1.1.1q-h8ffe710_0 --> anaconda::openssl-1.1.1s-h2bbff1b_0 None\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "joblib-1.1.1         | 414 KB    |            |   0% \n",
      "joblib-1.1.1         | 414 KB    | 3          |   4% \n",
      "joblib-1.1.1         | 414 KB    | ###8       |  39% \n",
      "joblib-1.1.1         | 414 KB    | #######7   |  77% \n",
      "joblib-1.1.1         | 414 KB    | ########## | 100% \n",
      "\n",
      "scikit-learn-1.2.0   | 7.7 MB    |            |   0% \n",
      "scikit-learn-1.2.0   | 7.7 MB    |            |   0% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | 1          |   2% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | 3          |   3% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | 6          |   6% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | 7          |   8% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #          |  10% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #3         |  13% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #5         |  15% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #7         |  17% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #9         |  19% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ##1        |  21% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ##2        |  23% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ##4        |  25% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ##6        |  26% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ##7        |  28% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ###        |  30% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ###2       |  33% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ###4       |  35% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ###6       |  36% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ###8       |  38% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ###9       |  40% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ####1      |  41% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ####3      |  43% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ####4      |  45% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ####6      |  46% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ####7      |  48% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ####9      |  50% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #####1     |  51% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #####2     |  53% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #####4     |  54% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #####6     |  56% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #####7     |  58% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #####9     |  59% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ######     |  61% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ######3    |  63% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ######5    |  65% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ######7    |  67% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ######9    |  69% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #######1   |  71% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #######2   |  73% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #######4   |  75% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #######7   |  77% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #######8   |  79% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ########   |  81% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ########2  |  83% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ########4  |  84% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ########6  |  86% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ########8  |  88% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ########9  |  90% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #########1 |  92% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #########3 |  93% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #########4 |  95% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #########6 |  97% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #########8 |  98% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | #########9 | 100% \n",
      "scikit-learn-1.2.0   | 7.7 MB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.2.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "threadpoolctl-2.2.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "ca-certificates-2023 | 158 KB    |            |   0% \n",
      "ca-certificates-2023 | 158 KB    | #          |  10% \n",
      "ca-certificates-2023 | 158 KB    | ########## | 100% \n",
      "ca-certificates-2023 | 158 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.1.1s       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1s       | 5.8 MB    |            |   0% \n",
      "openssl-1.1.1s       | 5.8 MB    | 2          |   3% \n",
      "openssl-1.1.1s       | 5.8 MB    | 5          |   5% \n",
      "openssl-1.1.1s       | 5.8 MB    | 7          |   8% \n",
      "openssl-1.1.1s       | 5.8 MB    | 9          |   9% \n",
      "openssl-1.1.1s       | 5.8 MB    | #2         |  12% \n",
      "openssl-1.1.1s       | 5.8 MB    | #4         |  14% \n",
      "openssl-1.1.1s       | 5.8 MB    | #6         |  17% \n",
      "openssl-1.1.1s       | 5.8 MB    | #8         |  18% \n",
      "openssl-1.1.1s       | 5.8 MB    | ##3        |  23% \n",
      "openssl-1.1.1s       | 5.8 MB    | ##6        |  27% \n",
      "openssl-1.1.1s       | 5.8 MB    | ##9        |  29% \n",
      "openssl-1.1.1s       | 5.8 MB    | ###1       |  32% \n",
      "openssl-1.1.1s       | 5.8 MB    | ###3       |  34% \n",
      "openssl-1.1.1s       | 5.8 MB    | ###6       |  36% \n",
      "openssl-1.1.1s       | 5.8 MB    | ###7       |  38% \n",
      "openssl-1.1.1s       | 5.8 MB    | ###9       |  40% \n",
      "openssl-1.1.1s       | 5.8 MB    | ####1      |  42% \n",
      "openssl-1.1.1s       | 5.8 MB    | ####3      |  44% \n",
      "openssl-1.1.1s       | 5.8 MB    | ####5      |  46% \n",
      "openssl-1.1.1s       | 5.8 MB    | ####7      |  47% \n",
      "openssl-1.1.1s       | 5.8 MB    | ####9      |  49% \n",
      "openssl-1.1.1s       | 5.8 MB    | #####1     |  51% \n",
      "openssl-1.1.1s       | 5.8 MB    | #####3     |  53% \n",
      "openssl-1.1.1s       | 5.8 MB    | #####5     |  55% \n",
      "openssl-1.1.1s       | 5.8 MB    | #####7     |  58% \n",
      "openssl-1.1.1s       | 5.8 MB    | ######     |  61% \n",
      "openssl-1.1.1s       | 5.8 MB    | ######3    |  64% \n",
      "openssl-1.1.1s       | 5.8 MB    | ######6    |  66% \n",
      "openssl-1.1.1s       | 5.8 MB    | ######8    |  68% \n",
      "openssl-1.1.1s       | 5.8 MB    | #######3   |  73% \n",
      "openssl-1.1.1s       | 5.8 MB    | #######6   |  76% \n",
      "openssl-1.1.1s       | 5.8 MB    | #######9   |  79% \n",
      "openssl-1.1.1s       | 5.8 MB    | ########1  |  82% \n",
      "openssl-1.1.1s       | 5.8 MB    | ########4  |  84% \n",
      "openssl-1.1.1s       | 5.8 MB    | ########6  |  86% \n",
      "openssl-1.1.1s       | 5.8 MB    | ########8  |  88% \n",
      "openssl-1.1.1s       | 5.8 MB    | #########  |  91% \n",
      "openssl-1.1.1s       | 5.8 MB    | #########2 |  93% \n",
      "openssl-1.1.1s       | 5.8 MB    | #########4 |  95% \n",
      "openssl-1.1.1s       | 5.8 MB    | #########7 |  97% \n",
      "openssl-1.1.1s       | 5.8 MB    | #########9 |  99% \n",
      "openssl-1.1.1s       | 5.8 MB    | ########## | 100% \n",
      "\n",
      "certifi-2022.12.7    | 153 KB    |            |   0% \n",
      "certifi-2022.12.7    | 153 KB    | #          |  10% \n",
      "certifi-2022.12.7    | 153 KB    | ########3  |  84% \n",
      "certifi-2022.12.7    | 153 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... \n",
      "\n",
      "    Windows 64-bit packages of scikit-learn can be accelerated using scikit-learn-intelex.\n",
      "    More details are available here: https://intel.github.io/scikit-learn-intelex\n",
      "\n",
      "    For example:\n",
      "\n",
      "        $ conda install scikit-learn-intelex\n",
      "        $ python -m sklearnex my_application.py\n",
      "\n",
      "\n",
      "done\n",
      "Retrieving notices: ...working... done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 22.9.0\n",
      "  latest version: 23.3.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c anaconda scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "65ce9317-f77d-4735-bda6-4e8124c4e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas generales\n",
    " \n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6d7e2-c6c8-4a88-b0d8-205b578599d2",
   "metadata": {},
   "source": [
    "Vamos a usar tres conjuntos de datos:\n",
    "* heart.csv\n",
    "* felicidad.csv\n",
    "* candy.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a27b88b-a189-406e-883d-01ea100f3831",
   "metadata": {},
   "source": [
    "## Introducción a PCA\n",
    "\n",
    "PCA = Principal Component Analysis\n",
    "\n",
    "Es una de las técnicas que podemos usar para reducir la dimensionalidad de nuestros features y elegir features que nos proporcionen la información mas importante.\n",
    "\n",
    "El principio de PCA es combinar distintos features de nuestro conjunto de datos en otros features artificiales pero que mantengan la misma información, por ejemplo, manteniendo la varianza entre los features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad94df35-3714-422c-921d-dbee31cda139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los módulos específicos\n",
    " \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    " \n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d3f43a-31a3-4cf3-9cbc-0fe5b36ef4f2",
   "metadata": {},
   "source": [
    "Lo que buscamos es una clasificación de pacientes binaria entre si un paciente tiene o no una enfermedad cardíaca tenindo en cuenta las caracteristicas del paciente, es decir, maximizando la información de los features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac8a9f0f-ae58-42cb-9916-52b1d727abab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   2     3       0  \n",
       "1   0     3       0  \n",
       "2   0     3       0  \n",
       "3   1     3       0  \n",
       "4   3     2       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos los datos del dataframe de pandas\n",
    "dt_heart = pd.read_csv('datasets\\heart.csv')\n",
    "\n",
    "# Imprimimos un encabezado con los primeros 5 registros\n",
    "dt_heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3b27cb0-e9a6-4e89-a507-ce3fba19b331",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>148</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>161</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
       "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
       "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
       "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
       "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
       "\n",
       "   ca  thal  \n",
       "0   2     3  \n",
       "1   0     3  \n",
       "2   0     3  \n",
       "3   1     3  \n",
       "4   3     2  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Guardamos nuestro dataset sin la columna de target\n",
    "dt_features = dt_heart.drop(['target'], axis=1)\n",
    "dt_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "548ca218-020e-4cba-985f-151d930917ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nuestro target será solo la columna de target\n",
    "dt_target = dt_heart['target']\n",
    "dt_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c337a48f-dba2-415c-86a4-c861a06fabd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizamos los datos\n",
    "## fit_transform lo que hace es cargar los datos, ajustar el modelo y\n",
    "## aplicar la transformación de una vez sobre el mismo conjunto de datos\n",
    "## Esto sobreescribe la variable dt_featur con los valores ya transformados\n",
    "## a los target no necesitamos hacerle esto\n",
    "dt_features = StandardScaler().fit_transform(dt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "676cb280-f3c8-442a-be10-4d1b2d8d73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partimos el conjunto de entrenamiento. Para añadir replicabilidad usamos el random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(dt_features, dt_target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a91ad362-cbf7-4fb5-ac8a-f8e23ba28c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(717, 13)\n",
      "(717,)\n"
     ]
    }
   ],
   "source": [
    "# Consultamos la forma de los x e y\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ef58eb9-7718-411a-8b7c-742d0cfec96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamamos y configuramos nuestro algoritmo pca\n",
    "## EL número de componentes es opcional, ya que por defecto si no le pasamos el \n",
    "## número de componentes lo asignará de esta forma:\n",
    "## a: n_components = min(n_muestras, n_features)\n",
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f87d6252-39b3-43b3-8cee-9e383572fad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustamos nuestro modelo con los datos de entrenamiento\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "528c1bd2-02e3-472d-80b9-584e01a6aee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>IncrementalPCA(batch_size=10, n_components=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IncrementalPCA</label><div class=\"sk-toggleable__content\"><pre>IncrementalPCA(batch_size=10, n_components=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "IncrementalPCA(batch_size=10, n_components=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Como haremos una comparación con incremental PCA, hacemos los mismos pasos\n",
    "## EL parámetro batch se usa para crear pequeños bloques, de esta forma podemos ir entrenandolos\n",
    "## poco a poco y combinarlos en el resultado final'''\n",
    "ipca = IncrementalPCA(n_components=3, batch_size=10)\n",
    "# Ajustamos\n",
    "ipca.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d5b77-1a2c-4ac2-a79a-f498bddc07fa",
   "metadata": {},
   "source": [
    "Una vez ajustados los datos vamos a poder medir la varianza de los componentes que obtengo al ejecutarse y lo vamos a ver con una representación gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4120f3c1-f717-4db2-9752-cd118bc7a946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# range(len(pca.explained_variance_) es el eje x: grafica en el rango desde 0 hasta el número de componentes\n",
    "## es decir, la longitud de los componentes que me sugirió pca\n",
    "# pca.explained_variance_ratio_ es el eje y: se ven los valores de importancia para nuestro modelo\n",
    "plt.plot(range(len(pca.explained_variance_)), pca.explained_variance_ratio_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5fc1ad-c6c4-42e4-b2ba-0bc8627e710a",
   "metadata": {},
   "source": [
    "Nos muestra 3 componenetes (0, 1 y 2) y nos dice que el componente 0 se lleva la mayor importancia, mas del 20% de la información, mientras que la segunda apenas supera el 12% y la tercera casi no tiene importancia.\n",
    "Podemos intuir que las dos primeras componentes son las que nos están aportando la mayor cantidad de información relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5bb68b7-afc6-4d0c-b0d4-16e9af2f9ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ahora vamos a configurar nuestra regresión logística\n",
    "logistic = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db49fc32-a4c8-40be-a749-5c71fb2cdd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos los datos de entrenamiento para pca\n",
    "# tanto en el conjunto de entrenamiento como de testeo\n",
    "dt_train = pca.transform(X_train)\n",
    "dt_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "852937f0-af93-4182-ab43-a84cfe385d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pasamos nuestro conjunto de entrenamiento por el modelo de clasificación\n",
    "logistic.fit(dt_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a22fe22-9910-4814-8b70-7bae9014fe0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE PCA:  0.7857142857142857\n"
     ]
    }
   ],
   "source": [
    "#Calculamos nuestra exactitud de nuestra predicción\n",
    "print(\"SCORE PCA: \", logistic.score(dt_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45ce071b-5fdd-46f6-a497-e83b418d20bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE IPCA:  0.8051948051948052\n"
     ]
    }
   ],
   "source": [
    "# Hacemos lo mismo para ipca\n",
    "dt_train = ipca.transform(X_train)\n",
    "dt_test = ipca.transform(X_test)\n",
    "logistic.fit(dt_train, y_train)\n",
    "print(\"SCORE IPCA: \", logistic.score(dt_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81aba278-8c7b-43f9-be2c-fd5efbeb4f72",
   "metadata": {},
   "source": [
    "Lo que hicimos fue, reducir los features del data set de 13 que tenía originalmente a 3 features artificiales mediante PCA y luego hicimos una clasificación binaria entre pacientes con o sin enfermedad cardíaca."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc693b3-e061-4ddf-b7a9-dff8e0b8d850",
   "metadata": {},
   "source": [
    "## Variaciones de PCA\n",
    "\n",
    "* IPCA: es PCA incremental y lo usamos cuando necesitamos poder computacional (lo vimos antes)\n",
    "* KPCA: cuando los datos no tienen una estructura separable linealmente y encontramos un Kernel que puede mapearlos\n",
    "\n",
    "### Kernel PCA\n",
    "\n",
    "Un KERNEL es una función matemática que toma mediciones que se comportan de manera no lineal y las proyecta en un espacio dimensional mas grande donde son linealmente separables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "056df2d2-9335-474a-82ca-95ff6ace4c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bbad70f2-703e-4fd1-8f2f-ab2bc25f095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos todo lo mismo que antes\n",
    "dt_heart = pd.read_csv('datasets\\heart.csv')\n",
    "dt_features = dt_heart.drop(['target'], axis=1)\n",
    "dt_target = dt_heart['target']\n",
    "dt_features = StandardScaler().fit_transform(dt_features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(dt_features, dt_target, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c75fdfd-9cb2-4f9a-a33d-864a63c37062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos una variable para el modelo\n",
    "kpca = KernelPCA(n_components=4, kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0d91cbe-02b2-4e9a-9c1d-839a596df2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KernelPCA(kernel=&#x27;poly&#x27;, n_components=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KernelPCA</label><div class=\"sk-toggleable__content\"><pre>KernelPCA(kernel=&#x27;poly&#x27;, n_components=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KernelPCA(kernel='poly', n_components=4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustamos los datos\n",
    "kpca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b54d8df-26fe-498e-89a8-1a012ae9fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos nuestro modelo a los datos de entrenamiento y prueba\n",
    "dt_train = kpca.transform(X_train)\n",
    "dt_test = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1246e611-8ad3-4a87-a000-ac20456ba402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Una vez reducida la dimensionalidad aplicamos el clasificador\n",
    "logistic = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4bcefb6-1281-4d51-aa0d-ab00d03a9ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE KPCA:  0.7987012987012987\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos\n",
    "logistic.fit(dt_train, y_train)\n",
    "print(\"SCORE KPCA: \", logistic.score(dt_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df3590a-c2bd-4382-be5d-0a61d9ba4238",
   "metadata": {},
   "source": [
    "## Regularización\n",
    "\n",
    "Consiste en reducir la complejidad del modelo a través de una penalización aplicada a sus variables o features mas irrelevantes.\n",
    "\n",
    "Tipos de recularización:\n",
    "* **L1 o Lasso**: reduce la complejidad a través de la **eliminación** de features que no aportan demasiado al modelo\n",
    "* **L2 o Ridge**: reduce la complejidad **disminuyendo** el impacto de los features que no aportan demasiado.\n",
    "* **ElasticNet**: combina las dos regulaciones anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3ec45af-b088-4936-9017-393e101d0890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos las funciones que necesitamos\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb4781c8-c17c-4840-8c8d-ae2e4d69b5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos del dataframe de pandas\n",
    "dataset = pd.read_csv('./datasets/felicidad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2b29a08-f735-4561-84a3-2f29de5e7ff8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>gdp</th>\n",
       "      <th>family</th>\n",
       "      <th>lifexp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption</th>\n",
       "      <th>dystopia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norway</td>\n",
       "      <td>1</td>\n",
       "      <td>7.537</td>\n",
       "      <td>7.594445</td>\n",
       "      <td>7.479556</td>\n",
       "      <td>1.616463</td>\n",
       "      <td>1.533524</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.635423</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.315964</td>\n",
       "      <td>2.277027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>7.522</td>\n",
       "      <td>7.581728</td>\n",
       "      <td>7.462272</td>\n",
       "      <td>1.482383</td>\n",
       "      <td>1.551122</td>\n",
       "      <td>0.792566</td>\n",
       "      <td>0.626007</td>\n",
       "      <td>0.355280</td>\n",
       "      <td>0.400770</td>\n",
       "      <td>2.313707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>3</td>\n",
       "      <td>7.504</td>\n",
       "      <td>7.622030</td>\n",
       "      <td>7.385970</td>\n",
       "      <td>1.480633</td>\n",
       "      <td>1.610574</td>\n",
       "      <td>0.833552</td>\n",
       "      <td>0.627163</td>\n",
       "      <td>0.475540</td>\n",
       "      <td>0.153527</td>\n",
       "      <td>2.322715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>4</td>\n",
       "      <td>7.494</td>\n",
       "      <td>7.561772</td>\n",
       "      <td>7.426227</td>\n",
       "      <td>1.564980</td>\n",
       "      <td>1.516912</td>\n",
       "      <td>0.858131</td>\n",
       "      <td>0.620071</td>\n",
       "      <td>0.290549</td>\n",
       "      <td>0.367007</td>\n",
       "      <td>2.276716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5</td>\n",
       "      <td>7.469</td>\n",
       "      <td>7.527542</td>\n",
       "      <td>7.410458</td>\n",
       "      <td>1.443572</td>\n",
       "      <td>1.540247</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.617951</td>\n",
       "      <td>0.245483</td>\n",
       "      <td>0.382612</td>\n",
       "      <td>2.430182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  rank  score      high       low       gdp    family    lifexp  \\\n",
       "0       Norway     1  7.537  7.594445  7.479556  1.616463  1.533524  0.796667   \n",
       "1      Denmark     2  7.522  7.581728  7.462272  1.482383  1.551122  0.792566   \n",
       "2      Iceland     3  7.504  7.622030  7.385970  1.480633  1.610574  0.833552   \n",
       "3  Switzerland     4  7.494  7.561772  7.426227  1.564980  1.516912  0.858131   \n",
       "4      Finland     5  7.469  7.527542  7.410458  1.443572  1.540247  0.809158   \n",
       "\n",
       "    freedom  generosity  corruption  dystopia  \n",
       "0  0.635423    0.362012    0.315964  2.277027  \n",
       "1  0.626007    0.355280    0.400770  2.313707  \n",
       "2  0.627163    0.475540    0.153527  2.322715  \n",
       "3  0.620071    0.290549    0.367007  2.276716  \n",
       "4  0.617951    0.245483    0.382612  2.430182  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bb75df1e-a7f1-4660-9102-37ed31dffb7a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>gdp</th>\n",
       "      <th>family</th>\n",
       "      <th>lifexp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption</th>\n",
       "      <th>dystopia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>5.354019</td>\n",
       "      <td>5.452326</td>\n",
       "      <td>5.255713</td>\n",
       "      <td>0.984718</td>\n",
       "      <td>1.188898</td>\n",
       "      <td>0.551341</td>\n",
       "      <td>0.408786</td>\n",
       "      <td>0.246883</td>\n",
       "      <td>0.123120</td>\n",
       "      <td>1.850238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>44.888751</td>\n",
       "      <td>1.131230</td>\n",
       "      <td>1.118542</td>\n",
       "      <td>1.145030</td>\n",
       "      <td>0.420793</td>\n",
       "      <td>0.287263</td>\n",
       "      <td>0.237073</td>\n",
       "      <td>0.149997</td>\n",
       "      <td>0.134780</td>\n",
       "      <td>0.101661</td>\n",
       "      <td>0.500028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.693000</td>\n",
       "      <td>2.864884</td>\n",
       "      <td>2.521116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.377914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.500000</td>\n",
       "      <td>4.505500</td>\n",
       "      <td>4.608172</td>\n",
       "      <td>4.374955</td>\n",
       "      <td>0.663371</td>\n",
       "      <td>1.042635</td>\n",
       "      <td>0.369866</td>\n",
       "      <td>0.303677</td>\n",
       "      <td>0.154106</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>1.591291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>5.279000</td>\n",
       "      <td>5.370032</td>\n",
       "      <td>5.193152</td>\n",
       "      <td>1.064578</td>\n",
       "      <td>1.253918</td>\n",
       "      <td>0.606042</td>\n",
       "      <td>0.437454</td>\n",
       "      <td>0.231538</td>\n",
       "      <td>0.089848</td>\n",
       "      <td>1.832910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>116.500000</td>\n",
       "      <td>6.101500</td>\n",
       "      <td>6.194600</td>\n",
       "      <td>6.006527</td>\n",
       "      <td>1.318027</td>\n",
       "      <td>1.414316</td>\n",
       "      <td>0.723008</td>\n",
       "      <td>0.516561</td>\n",
       "      <td>0.323762</td>\n",
       "      <td>0.153296</td>\n",
       "      <td>2.144654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>7.537000</td>\n",
       "      <td>7.622030</td>\n",
       "      <td>7.479556</td>\n",
       "      <td>1.870766</td>\n",
       "      <td>1.610574</td>\n",
       "      <td>0.949492</td>\n",
       "      <td>0.658249</td>\n",
       "      <td>0.838075</td>\n",
       "      <td>0.464308</td>\n",
       "      <td>3.117485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rank       score        high         low         gdp      family  \\\n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  155.000000   \n",
       "mean    78.000000    5.354019    5.452326    5.255713    0.984718    1.188898   \n",
       "std     44.888751    1.131230    1.118542    1.145030    0.420793    0.287263   \n",
       "min      1.000000    2.693000    2.864884    2.521116    0.000000    0.000000   \n",
       "25%     39.500000    4.505500    4.608172    4.374955    0.663371    1.042635   \n",
       "50%     78.000000    5.279000    5.370032    5.193152    1.064578    1.253918   \n",
       "75%    116.500000    6.101500    6.194600    6.006527    1.318027    1.414316   \n",
       "max    155.000000    7.537000    7.622030    7.479556    1.870766    1.610574   \n",
       "\n",
       "           lifexp     freedom  generosity  corruption    dystopia  \n",
       "count  155.000000  155.000000  155.000000  155.000000  155.000000  \n",
       "mean     0.551341    0.408786    0.246883    0.123120    1.850238  \n",
       "std      0.237073    0.149997    0.134780    0.101661    0.500028  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.377914  \n",
       "25%      0.369866    0.303677    0.154106    0.057271    1.591291  \n",
       "50%      0.606042    0.437454    0.231538    0.089848    1.832910  \n",
       "75%      0.723008    0.516561    0.323762    0.153296    2.144654  \n",
       "max      0.949492    0.658249    0.838075    0.464308    3.117485  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e1efe003-cb4e-4446-b0fd-853f89354fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a elegir los features que queremos usar para nuestro X y las etiquetas para nuestro Y\n",
    "X = dataset[['gdp', 'family', 'lifexp', 'freedom', 'corruption', 'generosity', 'dystopia']]\n",
    "y = dataset[['score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcb5e249-c627-4d0f-936f-7ea18e3938a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 7)\n",
      "(155, 1)\n"
     ]
    }
   ],
   "source": [
    "# Consultamos la forma de los x e y\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fab95310-4770-4fc3-a973-01e17797d9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# partimos el conjunto de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "777876df-f2f7-4321-b1ea-28763983e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos nuestro modelo\n",
    "model_lineal = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e7202b1-1404-4407-886c-86a01947f19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculamos la prediccion que nos da con el conjunto de prueba\n",
    "y_predict_linear = model_lineal.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d321578-6437-4726-bfd3-feece03791eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo con recularización y entrenamos\n",
    "# A mas grande alpha mas penalización\n",
    "modelLasso = Lasso(alpha=0.02).fit(X_train, y_train)\n",
    "y_predict_lasso = modelLasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00daaae1-fb53-41f1-82ca-0ad613616b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo mismo para Ridge\n",
    "modelRidge = Ridge(alpha=1).fit(X_train, y_train)\n",
    "y_predict_ridge = modelRidge.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29be5b7b-f043-411b-806a-159ed252eddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Loss:  8.28147579490474e-08\n",
      "Linear Laso:  0.0559459407171727\n",
      "Linear Ridge:  0.008581305990298313\n"
     ]
    }
   ],
   "source": [
    "# La métrica que elegimos es el error cuadrático\n",
    "# definimos las pérdidas para cada modelo\n",
    "linear_loss = mean_squared_error(y_test, y_predict_linear)\n",
    "print('Linear Loss: ', linear_loss)\n",
    "linear_laso = mean_squared_error(y_test, y_predict_lasso)\n",
    "print('Linear Laso: ', linear_laso)\n",
    "linear_ridge = mean_squared_error(y_test, y_predict_ridge)\n",
    "print('Linear Ridge: ', linear_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d58f596b-df8d-4537-8afa-d450fcc3ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coef LASSO\n",
      "[1.23881311 0.83275522 0.56373067 0.78502767 0.         0.19535702\n",
      " 0.88685095]\n",
      "================================================================================\n",
      "Coef RIDGE\n",
      "[[1.06876226 0.93685633 0.8636589  0.8909844  0.5875662  0.74116243\n",
      "  0.95402339]]\n"
     ]
    }
   ],
   "source": [
    "# Veamos como afectan los coeficientes de cada modelo, es decir, los que multiplican a los feature\n",
    "# para penalizar. En Lasso algunos tienen que ser cero y en Ridge cercano a cero pero no cero\n",
    "print('Coef LASSO')\n",
    "print(modelLasso.coef_)\n",
    "print('='*80)\n",
    "print('Coef RIDGE')\n",
    "print(modelRidge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352ba9d1-a01e-41d6-bc2f-70b87b737c47",
   "metadata": {},
   "source": [
    "Mirando los coeficientes podemos ver qué feature tiene mas peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "643bf7e6-e83b-41f5-b6ea-5b35f500aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Elastic:  1.5372256779647213\n",
      "Coef ELASTIC\n",
      "[0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Probamos ElasticNet\n",
    "from sklearn.linear_model import ElasticNet\n",
    "modelElastic = ElasticNet(random_state=0).fit(X_train, y_train)\n",
    "y_predict_Elastic = modelElastic.predict(X_test)\n",
    "linear_elastic = mean_squared_error(y_test, y_predict_Elastic)\n",
    "print('Linear Elastic: ', linear_elastic)\n",
    "print('Coef ELASTIC')\n",
    "print(modelElastic.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9ee66-3dbf-49af-a8d7-16054240dd72",
   "metadata": {},
   "source": [
    "## Regresión Robusta\n",
    "\n",
    "Cuando tenemos **valores atípicos**, un procedimiento es eliminarlos o sino transformarlos, pero a veces no tenemos mas opción que lidiar con ellos al momento de aplicar los modelos.\n",
    "\n",
    "Scikit-learn nos ofrece metaestimadores que nos permiten configurar distintos estimadores para lidiar con los valores atípicos de una manera fácil de usar. Estas técnicas se las conoce como **Regresión robusta**.\n",
    "\n",
    "Métodos:\n",
    "\n",
    "* **RANSAC**: Random Sample Consensus, que hace un muestreo aleatorio sobre los datos y busca muestras que mas datos \"buenos\" logra incluir. El modelo asume que los valores \"malos\" no tienen patrones específicos.\n",
    "\n",
    "* **Huber Reggresor**: No intenta sacar los valores atípicos y dejarlos fuera, sino penalizalos para disminuir su influencia en el modelo. Los datos son tratados cómo atípicos si el error absoluto de nuestra pérdida está por encima de un valor umbral llamado epsilon (en general epsilon es 1,35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8aaf607-2ca4-4332-b923-addcf84bf826",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import (RANSACRegressor, HuberRegressor)\n",
    "from sklearn.svm import SVR #Es el regresor que vamos a usar\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43900d6e-72d3-46a7-aecd-f4b333311b7e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>gdp</th>\n",
       "      <th>family</th>\n",
       "      <th>lifexp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption</th>\n",
       "      <th>dystopia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>H</td>\n",
       "      <td>163</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>I</td>\n",
       "      <td>164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>J</td>\n",
       "      <td>165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>K</td>\n",
       "      <td>166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>L</td>\n",
       "      <td>167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country  rank  score  high  low  gdp  family  lifexp  freedom  generosity  \\\n",
       "162       H   163    0.0   0.0  0.0  0.0     0.0     0.0      0.0         0.0   \n",
       "163       I   164    0.0   0.0  0.0  0.0     0.0     0.0      0.0         0.0   \n",
       "164       J   165    0.0   0.0  0.0  0.0     0.0     0.0      0.0         0.0   \n",
       "165       K   166    0.0   0.0  0.0  0.0     0.0     0.0      0.0         0.0   \n",
       "166       L   167    0.0   0.0  0.0  0.0     0.0     0.0      0.0         0.0   \n",
       "\n",
       "     corruption  dystopia  \n",
       "162         0.0       0.0  \n",
       "163         0.0       0.0  \n",
       "164         0.0       0.0  \n",
       "165         0.0       0.0  \n",
       "166         0.0       0.0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./RegresionRobusta/data/felicidad_corrupt.csv')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bd5513aa-fb5d-4dc4-b9c8-313399da2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos los feature con los que vamos a trabajar haciendo drop a las que no queremos\n",
    "X = dataset.drop(['country', 'score'], axis=1)\n",
    "y = dataset['score']\n",
    "# Hacemos la partición\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d3cd5929-09b7-479e-9565-7cc9249488f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos todos los estimadores dentro de un diccionario\n",
    "## RANSAC no es un estimador es un metaestimado, donde podemos usar varios estimadores en el\n",
    "## pero en este caso lo vamos a dejar sin parámetros lo que por defecto es una regresión lineal\n",
    "estimadores = { 'SVR'    : SVR(gamma='auto', C=1.0, epsilon=0.1),\n",
    "                'RANSAC' : RANSACRegressor(),\n",
    "                'HUBBER' : HuberRegressor(epsilon=1.35)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a655b594-f63b-4fad-9cd9-c68a22ee47fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SVR\n",
      "MSE:  0.07455771301888525\n",
      "================================================================================\n",
      "RANSAC\n",
      "MSE:  1.2756405701033106e-19\n",
      "================================================================================\n",
      "HUBBER\n",
      "MSE:  2.317373092927481e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\.conda\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "for name, estimador in estimadores.items():\n",
    "    estimador.fit(X_train, y_train)\n",
    "    predictions = estimador.predict(X_test)\n",
    "    print('='*80)\n",
    "    print(name)\n",
    "    print('MSE: ', mean_squared_error(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd241c1a-655c-477e-8c54-8d90322032c8",
   "metadata": {},
   "source": [
    "RANSAC y HUBBER tienen errore muchos mas bajos que SVR, lo que nos muestra que los valores atípicos sí tienen un efecto en nuestro resultado final."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f872dd3-0c6c-4eb8-be2d-781824622f34",
   "metadata": {},
   "source": [
    "## Métodos de ensamble\n",
    "\n",
    "Funcionan muy bien cuando queremos usar varios estimadores y llegar a una única conclusión. Es decir, se prueban distintos algorítmos con distintas configuraciones y se aplica un método para lograr un consenso entre los resultados.\n",
    "\n",
    "Dos estrategias:\n",
    "\n",
    "* **Bagging**: viene de Bootstrap Aggregation y consiste en tener en paralelo varios modelos, cada uno con un resultado y que por algún método de consenso tome un resultado final. Ejemplos de métodos de consenso son: votación, random Forest, o cualquier familia de modelos de ML.\n",
    "* **Boosting**: busca fortalecer gradualmente un modelo de aprendizaje usando siempre el error residual de las etapas anteriores. Son ejemplo de esto: AdaBoost, Gradient Tree Boosting y XSBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db1a424-b8f1-42ed-a61c-e2761c428c4d",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "740c3d0c-ada6-41d2-a2d3-dd6b78bf99ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn. ensemble import BaggingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea46d369-0fe3-4662-bcc2-e51b81fc4fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_heart = pd.read_csv('./datasets/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f7ee30-f977-4104-beee-d7eb05e0d166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1025.000000\n",
       "mean        0.513171\n",
       "std         0.500070\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max         1.000000\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Las estadísticas nos muestran que la columna se compone de 0 y 1 solamente.\n",
    "dt_heart['target'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a183c499-3359-4beb-81d3-98449d8e53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos los feature con los que vamos a trabajar haciendo drop a las que no queremos\n",
    "X = dt_heart.drop(['target'], axis=1)\n",
    "y = dt_heart['target']\n",
    "# Hacemos la partición\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8eee784-6234-410a-b348-ea0040e11c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.6908077994428969\n"
     ]
    }
   ],
   "source": [
    "# Vamos a usar un clasificador knn y lo vamos a guardar en una variable\n",
    "knn_class = KNeighborsClassifier().fit(X_train, y_train) #entrenamos y ajustamos\n",
    "knn_pred = knn_class.predict(X_test) # predecimos\n",
    "print('Accuracy score: ', accuracy_score(knn_pred, y_test)) # calculamos la metrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e09011b9-98ad-4f78-a0de-e31a5faa834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marco\\.conda\\envs\\mlenv\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.724233983286908\n"
     ]
    }
   ],
   "source": [
    "# Vamos a comparar el método anterior con el de Bagging\n",
    "# Este metaclasificador nos va a pedir parámetros para configurarlo\n",
    "# base_estimator: es en qué estimador esta basado nuestro método\n",
    "# n_estimators: la cantidad de estimadores, cuantos de estos modelos vamos a usar\n",
    "\n",
    "bag_class = BaggingClassifier(base_estimator=KNeighborsClassifier(),\n",
    "                             n_estimators=50).fit(X_train, y_train)\n",
    "bag_pred = bag_class.predict(X_test) # predecimos\n",
    "print('Accuracy score: ', accuracy_score(bag_pred, y_test)) # calculamos la metrica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f52f7-3e14-4c73-ab2d-1b71c10d4bfa",
   "metadata": {},
   "source": [
    "Aún cuando no teníamos un modelo muy bueno, vemos que usando los métodos de ensamble llegamos a mejores resultados.\n",
    "Por otro lado, muchas veces un modelo por sí solo no es tan poderoso, que si ese mismo modelo muchas veces con diferentes configuraciones y parámetros y un método de conceso aplicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ca4f0ae-f5dc-4bb9-9f0a-1b88f599d37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importo otros modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc862f22-e9f2-4cda-8982-be3afd31872a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para ignorar los warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b4651b4-3955-40fb-ae1a-6a2b7d521353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SCORE Bagging with LogisticRegression : 0.7994428969359332\n",
      "================================================================================\n",
      "SCORE Bagging with SVC : 0.6657381615598886\n",
      "================================================================================\n",
      "SCORE Bagging with LinearSVC : 0.8105849582172702\n",
      "================================================================================\n",
      "SCORE Bagging with SGD : 0.6824512534818942\n",
      "================================================================================\n",
      "SCORE Bagging with KNN : 0.7353760445682451\n",
      "================================================================================\n",
      "SCORE Bagging with DecisionTreeClf : 0.9749303621169917\n",
      "================================================================================\n",
      "SCORE Bagging with RandomTreeForest : 0.9832869080779945\n"
     ]
    }
   ],
   "source": [
    "#Para probar varios estimadores\n",
    "estimators = {\n",
    "        'LogisticRegression' : LogisticRegression(),\n",
    "        'SVC' : SVC(),\n",
    "        'LinearSVC' : LinearSVC(),\n",
    "        'SGD' : SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5),\n",
    "        'KNN' : KNeighborsClassifier(),\n",
    "        'DecisionTreeClf' : DecisionTreeClassifier(),\n",
    "        'RandomTreeForest' : RandomForestClassifier(random_state=0)\n",
    "    }\n",
    "\n",
    "# Creo un diccionario para graficar los resultados luego\n",
    "accuracy_scores = {}\n",
    "\n",
    "for name, estimator in estimators.items():\n",
    "    bag_class = BaggingClassifier(base_estimator=estimator, n_estimators=50).fit(X_train, y_train)\n",
    "    bag_predict = bag_class.predict(X_test)\n",
    "    accuracy_scores[name] = accuracy_score(bag_predict, y_test) #aca es donde guardo los resultados\n",
    "    print('='*80)\n",
    "    print('SCORE Bagging with {} : {}'.format(name, accuracy_score(bag_predict, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3f540b2-b19c-40ec-a512-1bc3cb122ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAFVCAYAAADFb2n2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8A0lEQVR4nO3dd7gcZfnG8e9NQuidSG/SUamhKUhoSg8iIL2DCCgoUi2AWABFsYCACAjSlV5FEKVD6B350XvooRN4fn8875LJesomeza7J+f+XNe5zu7O7Ow7s7PzzNsVEZiZmU2oydqdADMz698cSMzMrCkOJGZm1hQHEjMza4oDiZmZNcWBxMzMmjJgA4mkgyWd1IfbO1TSXyfwvSFpob5KSy+fdbykH3VCWpohabikZyvPH5A0vDyWpFMkvS7ptnalcWKqPx4t2P7bkj7bqu33BUk7SLqhj7fZJ8e1evwkTSXpEklvSjpP0taS/tF8arv97C6vdZK+JOk2STM1+xmDm93AhJD0JDAb8HHl5VMjYq8Wfd5w4K8RMXfttYj4eWX5/MATwOQRMaYVaZhQknYAdomIVfpiexGxe19sp9NExOcqT1cB1gbmjoh3JmY6OvlcakZETFt7LOlU4NmI+GH7UtS/VI8fsCl5/Zulco6c0cLP/nn9a5LmAX4ObBARrzf7GW0JJMWGEfHPNn6+dShJg5u8CM8HPDkhQaQPPnuS4uPREvMBj7bzuEbEM8BqfbnBif4HPAms1c2yPwJ/qzw/ErgGEDATcCkwCni9PJ67su7MwCnA82X5hcA0wHvAJ8Db5W9O4FAylwLwNBCV5StXl5d15i/rDC7PFwD+DYwGrgb+UF2/i/3aFXgMeA24GJizsiyA7wCPA68AvySLHRcH3idzbm8Db5T1pwB+VdL9EnA8MFVZNhx4FtgXeBl4Adix8lmnAj+tPN+vrPM8sFNJy0Jl2frAXcBbwDPAoT3sX+1zDy778CSwdWX5DMBp5bt7CvghMFlZtgNwI/Cbcnx+2sX2pyppfx14sKT72fpzCti57pgdVpZvANwNvAHcBCxZ994DgHuBD8gbrJXKem8A9wDDK+tfBxxe0jwa+Acwa3fnUnl9J+Chkv6rgPnK6yr7/TLwZknD57s5xjuWbYwmz5Vv1h//yvNly3c3GjgPOKfue+/tfNwT+C/wROW1hYDdgI+AD8v+XVI5hvuV9L8D/Jm8676ipOGfwEyVz9gIeKAc3+uAxSvLDgCeK+97BFizm+MxS0n7W8Bt5Tu5obJ8MfK3+VrZzuY9nL//c+3o5rgeCPxfSduDwNcqyxYirwlvkr+Bc+qO6ULAYeXYfVSO387k+V9N9+cq6X4JOLi8vgJwczlmL5DXnCENvO9Qxr2W9XTsnwS+X77HN8nzZsper+l9FRzG54+eA8nUwKPl4K5avpC5KyfO18s605E/kAsr772s7PhMwOTAal2dDPUHl7og0c3BH2ed8oX+mryof7mcWF0GEmCNsh/LlvV/D/yn7iT7F3kyz1v2f5cYe5G9oW57x5A/oJnLcbgE+EVlX8cAPynHYD3gXcqPmEogAdYpJ9znyYB7JuMGkuHAF8igtmRZd+Nu9rH2ubVjshp5QVm0LD8NuKikd/6yjztX9nEM8G3yIj5VF9s/Ari+7PM8wP10EUi6OmbluL8MrAgMArYv609Ree/dZbtTAXMBr5ZjNxlZTPYqMLSsfx15MVmkrH8dcEQP59LG5EV78bJ/PwRuKsu+CtwBzEgGlcWBObo5xusDC5b1Vivf67L15zgwhAzWe5PnwCbkxav2vTdyPl5djvVUlddq58Wp1AX7cgxvIYPHXOV43wksUz7jWuCQsu4i5Lmxdknf/uX4DAEWJW9a5qwczwW7OR5nA+eS5+7nyeBzQ1k2TdnOjuWYL1v2+XPdbKuhawewGXkjOhnwjbIfc5RlZwE/KMumBFapO6a143co415bdqikezoySOxbtjEdsGJZthx5gzO4HJeHgH0aeN+nn9fTsa98j7eVfZy5fMbuvV7T+zJANPpXEvs2GRFrf7tWlq9ARtWngC172M7SwOvl8RxkrmOmLtYb52To4uDOz3gEEvJiPwaYprL8TLoPJH8Gjqo8n5a8I5m/cpKtU1m+B3BNNxdFlRNhwcprKzP2znE4mQOr7svLwEr1FwHgZMoFsHKSfXrCd7EfxwC/6WbZ8C6OybnAj8iL9wfAEpVl3wSuq+zj072cM4/XHaPdaDyQ/BE4vG57jzD2YvEksFNl2QHA6XXrXwVsXx5fB/yw7vu6sodz6QpK0CzPJyODwHzkRf1R8gIx2Xj+ji4E9q4/x8kbm+cAVda9ofK9N3I+rlH3WY0EkmoO9O/AHyvPv83Yu/wfAefWHY/nyj4sRJ6va5H1TN3t+6CS5sUqr/2csRfkbwDX173nBEowq3t9vK4ddcvvBkaUx6cBJ1IpJenm+B1K94FkS+CuBr//fYALensf417ruj32le9xm8ryo4Dje0tLO1ttbRwRM1b+/lRbEBG3kRcOkRcjACRNLekESU9Jegv4DzCjpEHk3eRr0QcVRw2Ykwxg1TL4p3pZ/9PlEfE2eYc7V2WdZ+q2NWc32xpK5sjukPSGpDeAK8vrNa/GuOWv75IXi67SVf+5n5K0oqR/SRol6U1gd2DWbtIFXR+TOct7anfJ1WXd7X9XekxrL+YD9q0dr3LM5mHcY/xM3fqb1a2/CnnBqXmx8ri741vd3m8r23qNPLfniohrySKKY4GXJJ0oafquNiJpXUm3SHqtbGc9uv4+5gSei3Il6GL/xvd8bNRLlcfvdfG8dozqP/+T8nlzRcRj5AXyUOBlSWdL6uq3MJS8qevunJgPWLHuO9wamL2LbTV87ZC0naS7K9v8PGO/g/3J7/W20opwp962101a/q+bz15E0qWSXizXv59XPrvb99Xp9thX1hmfcxvo0Oa/kvYks8PPk19Ozb5k1nfFiJievPOC/PKeAWaWNGMXm4wuXutt+TvkBbumegK+AMwkaZrKa/P2sP3nyRM7E5vvm4W8E6iZp25bz3eTtlfIH+XnKkF4hhi3VUijXujic6vOJIvQ5omIGci6GPWwva6OyfMlzR9ROQZlWXX/e/uOektrT54BflZ34zJ1RJzVzec/Q+ZIqutPExFHNPBZXe3HM2R9RnV7U0XETQAR8buIWI4s416ErGsYh6QpyLv8XwGzRcSMwOV0/X28AMwlqbqseuwaOR97+j56+656U//5Kul7DiAizoxspThf+awju9jGKDIH3N058Qzw77pjPm1EfKuLbfV07fiUpPmAPwF7kS2uZiSLWFXS/WJE7BoRc5I57uMmoCn9M2TxZVf+CDwMLFyufwcz9vvv6X1VPR77CdVxgUTSIsBPgW2AbYH9JS1dFk9HXkTfkDQzcEjtfRHxAlmEcJykmSRNLqkWaF4CZpE0QzcfO4rM2lbbyd8NfFnSvOV9B1U+6ylgJHCYpCGSVgE27GG3zgR2lLR0uSD8HLg1Ip6srLNfSfc8ZNn2OZW0zy1pSPnsT8iT+TeSPlOO2VySvtrD53fnXGAHSUtImprK8SymI+/U3pe0ArBVA9usHZNVyQru8yLi4/JZP5M0XflBfg8Yn3435wIHlWM0N1lU0qg/AbuXHJYkTSNpfUnTdbP+X4ENJX1V0iBJUyr7E8zdzfpVXZ1Lx5e0fw5A0gySNiuPly/pmpy8eak1FKg3hLy5GgWMkbQu8JVu0nBz2cZekgZLGkEWF9c0cj725KW6/Rtf5wLrS1qz7Pe+ZNHnTZIWlbRGSdf75O/9f45HOafOBw4tJRVLkHVfNZcCi0jatlwLJi/HevEuttXTtaNqGjKwjQKQtCOZI6E836xyjrxe1u3qu+zJpcDskvaRNEX5vaxYlk1HNix4W9JiwLcafF9Vt8d+PNM5jnYGkkuUnXRqfxdIGkz+iI+MiHsi4r9k1D29nFjHkJWbr5AVe1fWbXNb8s73YbKcdR+AiHiYrAh7vGRJx8kqR8S7wM+AG8vylSLiavJifi9ZGXpp3WdtRVbevkZegE/rbkcj4hqybPLv5N3igsAWdatdVD7nbrLi78/l9WvJFhYvSnqlvHYAWUF2S8ni/pPMqY2XiLiCPKbXlu1dW7fKHsBPJI0GfkylmLEbL5I/oOfJdvG7l2MPeeF/hyyyvIG8mJ08Hsk9jMySP0G2kjq90TdGxEiyldIfSvoeI8ulu1v/GWAEee6NIu/29qOB30s359IF5F312eX7uh9Yt7xlejLQvV7271Uy11G/3dFky75zy7pbkbnFrtLwIVnBvjNZ/7gNef5+UJY3cj725M/AEmX/LhyP99XS90hJ0+/J3/KGZHeAD8lgeUR5/UXgM+T30JW9yGKXF8l6m1MqnzGaDLRbkOfji+R3MEU32+ry2lGX7geBo8lA/RLZEOXGyirLA7dKepv8bvaOiCe6Ow5dKelemzwmL5It51Yvi79Pfu+jyXPmnAbfV91+T8d+gmncYlSzCaMuOn1a55B0K1lpekqvK5uNp44r2jKz5klaTdLspWhre7L5dn0O3qxPtLNnu5m1zqJkMdi0ZGueTUtdgFmfc9GWmZk1xUVbZmbWFAcSMzNrSr+rI5l11llj/vnnb3cyzMz6lTvuuOOViBja+5rjr98Fkvnnn5+RI0e2OxlmZv2KpPEZVmi8uGjLzMya0rJAIulkSS9Lur+b5ZL0O0mPSbpX0rKtSouZmbVOK3Mkp5LzXXRnXWDh8rcbOSCZmZn1My0LJBHxH3Icqu6MAE6LdAs5HPwcPaxvZmYdqJ11JHMx7lwCzzLumPhmZtYPtDOQdDWPQpfd7CXtJmmkpJGjRo1qcbLMzGx8tDOQPMu4k9LMzdjJnMYRESdGxLCIGDZ0aEuaQZuZ2QRqZyC5GNiutN5aCXjTg8qZmfU/LeuQKOksYDgwq6RnycmfJgeIiOPJaULXIycZehfYsVVpMTObEDqsp5mlJ744pDMH2W1ZIImILXtZHsCerfp8MzObOPrdEClm1j+ps27u8QwafcdDpJiZWVMcSMzMrCkOJGZm1hQHEjMza4oDiZmZNcWBxMzMmuJAYmZmTXEgMTOzpjiQmJlZUxxIzMysKQ4kZmbWFAcSMzNrigOJmZk1xYHEzMya4kBiZmZNcSAxM7OmOJCYmVlTHEjMzKwpDiRmZtYUBxIzM2uKA4mZmTXFgcTMzJriQGJmZk1xIDEzs6Y4kJiZWVMcSMzMrCkOJGZm1hQHEjMza4oDiZmZNcWBxMzMmuJAYmZmTXEgMTOzprQ0kEhaR9Ijkh6TdGAXy2eQdImkeyQ9IGnHVqbHzMz63uBWbVjSIOBYYG3gWeB2SRdHxIOV1fYEHoyIDSUNBR6RdEZEfNiqdFnrSe1Owbgi2p0Cs0lbK3MkKwCPRcTjJTCcDYyoWyeA6SQJmBZ4DRjTwjSZmVkfa2UgmQt4pvL82fJa1R+AxYHngfuAvSPikxamyczM+lgrA0lXBRz1hQxfBe4G5gSWBv4gafr/2ZC0m6SRkkaOGjVqwhOkzvozM5sUtDKQPAvMU3k+N5nzqNoROD/SY8ATwGL1G4qIEyNiWEQMGzp0aMsSbGZm46+VgeR2YGFJC0gaAmwBXFy3ztPAmgCSZgMWBR5vYZrMzKyPtazVVkSMkbQXcBUwCDg5Ih6QtHtZfjxwOHCqpPvIorADIuKVVqXJzMz6XssCCUBEXA5cXvfa8ZXHzwNfaWUazMystdyz3czMmuJAYmZmTXEgMTOzpjiQmJlZUxxIzMysKQ4kZmbWFAcSMzNrigOJmZk1paUdEs2sNTpt0E/P+TKwOUdiZmZNcSAxM7OmOJCYmVlTHEjMzKwpDiRmZtYUBxIzM2uKA4mZmTXFgcTMzJriQGJmZk1xIDEzs6Z4iBQzPOSIWTOcIzEzs6Y4kJiZWVMcSMzMrCmuI+lwLrs3s07nHImZmTXFgcTMzJriQGJmZk1xIDEzs6Y4kJiZWVMcSMzMrCkOJGZm1hQHEjMza4oDiZmZNaXHnu2Slu1peUTc2cv71wF+CwwCToqII7pYZzhwDDA58EpErNZjis3MrKP0NkTK0eX/lMAw4B5AwJLArcAq3b1R0iDgWGBt4FngdkkXR8SDlXVmBI4D1omIpyV9ZgL3w8zM2qTHoq2IWD0iVgeeApaNiGERsRywDPBYL9teAXgsIh6PiA+Bs4ERdetsBZwfEU+Xz3t5QnbCzMzap9E6ksUi4r7ak4i4H1i6l/fMBTxTef5sea1qEWAmSddJukPSdg2mx8zMOkSjo/8+JOkk4K9AANsAD/Xynq7Gra0fO3YwsBywJjAVcLOkWyLi0XE2JO0G7AYw77zzNphkMzObGBrNkewIPADsDewDPFhe68mzwDyV53MDz3exzpUR8U5EvAL8B1iqfkMRcWIpVhs2dOjQBpNsZmYTQ0M5koh4H/hN+WvU7cDCkhYAngO2IOtEqi4C/iBpMDAEWHE8P8PMzNqsoUAi6Qn+t1iKiPhsd++JiDGS9gKuIpv/nhwRD0javSw/PiIeknQlcC/wCdlE+P4J2A8zM2uTRutIhlUeTwlsBszc25si4nLg8rrXjq97/kvglw2mw8zMOkxDdSQR8Wrl77mIOAZYo7VJMzOz/qDRoq1qD/fJyBzKdC1JkZmZ9SuNFm0dXXk8BngC2Lzvk2NmZv1No4Fk54h4vPpCaY1lZmYDXKP9SP7W4GtmZjbA9Db672LA54AZJG1SWTQ92XrLzMwGuN6KthYFNgBmBDasvD4a2LVFaTIzs36kx0ASERcBF0laOSJunkhpMjOzfqS3oq39I+IoYCtJW9Yvj4jvtCxlZmbWL/RWtFUb4XdkqxNiZmb9U29FW5eUh+9GxHnVZZI2a1mqzMys32i0+e9BDb5mZmYDTG91JOsC6wFzSfpdZdH0ZA93MzMb4HqrI3merB/ZCLij8vpo4LutSpSZmfUfvdWR3APcI+kC4J2I+BhA0iBgiomQPjMz63CN1pH8g5xTvWYq4J99nxwzM+tvGg0kU0bE27Un5fHUrUmSmZn1J40Gkneqc5JIWg54rzVJMjOz/qTRYeT3Ac6T9Hx5PgfwjZakyMzM+pWGAklE3F5GAl4UEPBwRHzU0pSZmVm/0GiOBDKILEEOH7+MJCLitNYky8zM+otG52w/BBhOBpLLgXWBGwAHEjOzAa7RyvZNgTWBFyNiR2Ap3I/EzMxoPJC8FxGfAGMkTQ+8DHy2dckyM7P+otE6kpGSZgT+RA6V8jZwW6sSZWZm/Uejrbb2KA+Pl3QlMH1E3Nu6ZJmZWX/RUNGWpJ1rjyPiSeCBUgFvZmYDXKN1JGtKulzSHJI+D9wCTNfCdJmZWT/RaNHWVpK+AdwHvAtsGRE3tjRlZmbWLzRatLUwsDfwd+BJYFtJHrTRzMwaLtq6BPhRRHwTWA34L3B7y1JlZmb9RqPNf1eIiLcAIiKAoyVd3LpkmZlZf9FjjkTS/gAR8ZakzeoW79iyVJmZWb/RW9HWFpXHB9UtW6e3jUtaR9Ijkh6TdGAP6y0v6WNJm/a2TTMz6yy9BRJ187ir5+MuzHndjyUHeFwC2FLSEt2sdyRwVa+pNTOzjtNbIIluHnf1vN4KwGMR8XhEfAicDYzoYr1vk63BXu5le2Zm1oF6q2xfStJbZO5jqvKY8nzKXt47F/BM5fmzwIrVFSTNBXwNWANYvtFEm5lZ5+gxkETEoCa23VXRV30u5hjggIj4WOq+pEzSbsBuAPPOO28TSTIzs742PjMkjq9ngXkqz+cGnq9bZxhwdgkiswLrSRoTERdWV4qIE4ETAYYNG9ZbkZqZmU1ErQwktwMLS1oAeI5sAbZVdYWIWKD2WNKpwKX1QcTMzDpbywJJRIyRtBfZGmsQcHJEPCBp97L8+FZ9tpmZTTytzJEQEZeTc7xXX+sygETEDq1Mi5mZtUajY22ZmZl1yYHEzMya4kBiZmZNcSAxM7OmOJCYmVlTHEjMzKwpDiRmZtYUBxIzM2uKA4mZmTXFgcTMzJriQGJmZk1xIDEzs6Y4kJiZWVMcSMzMrCkOJGZm1hQHEjMza4oDiZmZNcWBxMzMmuJAYmZmTXEgMTOzpjiQmJlZUxxIzMysKQ4kZmbWFAcSMzNrigOJmZk1xYHEzMya4kBiZmZNcSAxM7OmOJCYmVlTHEjMzKwpDiRmZtYUBxIzM2uKA4mZmTXFgcTMzJrS0kAiaR1Jj0h6TNKBXSzfWtK95e8mSUu1Mj1mZtb3WhZIJA0CjgXWBZYAtpS0RN1qTwCrRcSSwOHAia1Kj5mZtUYrcyQrAI9FxOMR8SFwNjCiukJE3BQRr5entwBztzA9ZmbWAq0MJHMBz1SeP1te687OwBVdLZC0m6SRkkaOGjWqD5NoZmbNamUgURevRZcrSquTgeSArpZHxIkRMSwihg0dOrQPk2hmZs0a3MJtPwvMU3k+N/B8/UqSlgROAtaNiFdbmB4zM2uBVuZIbgcWlrSApCHAFsDF1RUkzQucD2wbEY+2MC1mZtYiLcuRRMQYSXsBVwGDgJMj4gFJu5flxwM/BmYBjpMEMCYihrUqTWZm1vdaWbRFRFwOXF732vGVx7sAu7QyDWZm1lru2W5mZk1xIDEzs6Y4kJiZWVMcSMzMrCkOJGZm1hQHEjMza4oDiZmZNcWBxMzMmuJAYmZmTXEgMTOzpjiQmJlZUxxIzMysKQ4kZmbWFAcSMzNrigOJmZk1xYHEzMya4kBiZmZNcSAxM7OmOJCYmVlTHEjMzKwpDiRmZtYUBxIzM2uKA4mZmTXFgcTMzJriQGJmZk1xIDEzs6Y4kJiZWVMcSMzMrCkOJGZm1hQHEjMza4oDiZmZNcWBxMzMmuJAYmZmTWlpIJG0jqRHJD0m6cAulkvS78ryeyUt28r0mJlZ32tZIJE0CDgWWBdYAthS0hJ1q60LLFz+dgP+2Kr0mJlZa7QyR7IC8FhEPB4RHwJnAyPq1hkBnBbpFmBGSXO0ME1mZtbHBrdw23MBz1SePwus2MA6cwEvVFeStBuZYwF4W9IjfZvU8TYr8EqzG5H6ICWNc5onjv6W5v6WXhjIaT60qUTP1+znd6eVgaSrPY4JWIeIOBE4sS8S1RckjYyIYe1Ox/hwmieO/pbm/pZecJo7USuLtp4F5qk8nxt4fgLWMTOzDtbKQHI7sLCkBSQNAbYALq5b52Jgu9J6ayXgzYh4oX5DZmbWuVpWtBURYyTtBVwFDAJOjogHJO1elh8PXA6sBzwGvAvs2Kr09LGOKWYbD07zxNHf0tzf0gtOc8dRxP9USZiZmTXMPdvNzKwpDiRmZtYUB5IBRtJMkqZqdzpapezf1O1OR38kafZ2p6HdJE3e7jT0Rw4kA4ikdYCTgA0kzdLu9PQ1SeuSlZqbSpqh3empkdTxvzNJcwM/kLRDu9PSLpK+BvxJmshdFftYLf0Tcz86/gQf6ConxRTN3C1J2gD4NfBn4JKIeLWPktgRJG0IHEUGkvMi4s02pmUeSYvUBiGNiE/6wcXpbeBRYClJW7c7MRNbubH6NnAK8Nn+mquVND0wRXk610T7XLfa6nySRgC7AC8Cp0fEf8bjvQKGkmOdHVp9r6TJIuKTvk7vxCZpKHAWcEhE3ChJERHt2D9J6wM/IC/MU5NN39eLiNdr6ZqY6emNpHmA9yNilKRpgW8AywC3RMRf25u6iUfSdMDvgU+AOYAt2nkzMiHKQLlbAlORv/n1gDWAj1p93jlH0uEkLQLsDZwG3AH8WdIajb6/nECvk+P8PCxpUK2opXaRnQQGynwHGA08Xc21VfZv1omRCElfBQ4DDgQ2iIhVgKeAqyXNUIJbx+RMJA0j03eVpC2A4RHxZ+ABsjPxdm1N4EQgaZik1SNiNJkj2xS4th8GEUXEx8CVwPfI3NVeEfHhxLh5cSDpYJK+APwGuDEiziudOA8D/ijpKw28f1VJ+wEfAwsCX4yIj0tRy6CyzkzAamX0gX5F0lqSvhkR7wKfARaIiI/KssnK/5mBjSRN0cOm+iItSwFXALuXXF8tWG8BPA5cUp53TI4kIkaSnYKXJnNP35V0HLAsMARYQ9LX25fCiWI54BeSVgVuA7YH1pa0c39plFKX0x0MHEPeDKwhabb6dVuRBgeSzvZfYBQwTNK85YT5K3AEcJKkWXo5MaYEViG/518Du5cfDGQWHmBzYEOyCKa/mRzYofzgTwF+L2mZuov1JsDqtPhcj4h7gJvIYi0i4n1JU5bFO8Gnucu2k7SapGMAImIDMgBuHBFrksfxBWBVYDvg25KmaVdaW0XSSpI2iogTgJOBA4AxEXEBcCSwLbBZp9eVVIOIpD3InMhJZPrXAvYoy7aStGLLbmQiwn8d8sfYOqthwDrAUuX5CcDxwDyVdedsYHsLkBeJNcrz/YBrgM2A+ckLxT3AEu3e9wk4VpMBs5GNB9Yqrx0EPFh+QIsDWwN3A59rYToWA1asPL8auKbyfHJgmvI9zN3u41bSNDvwBvDLymvXA1dUzy/ybn3hdqe3Bfu/LvAIWe+4VHntO+W7W708Xw24C9iq3eltcJ92BkbWXSNmBS4ETiXrV1v2O2/7AfDf/5wQ65cT+E/ApcDR5fXjywkxby/vn7ru+Z5kln1GYDoyB3IT8BeyWOML7d7n8Tw+09Q9P7AEiyHl+S7AP8jK90uAJVuYlnXKsf0dsHTl9X+S5ey159sB/wJmavfxq6RpTuBp4JjKa/8Crm532lq83yuSY/ut2sWy75RzZ3h5vgowX7vT3Mv+TEaWPJxO5r5nJ+tULwG+RRZRrlwNMC1JR7sPxED/A2YGPlMeT1FOgNUryy4E9iknxNn0cHdNzkp5bPUuipzz5Xhgncpr05f/07Z7/8fzWC0MnAuMqHv9dGAbxuboZig/sJbtH9ki5j5g5W6W/7N8d18Hbm13wCaL924HdgVWqpxfjwC/rqx3F3Bhu7/rFh6HHYFflMe182VwZflO5J39/wSaTvmrpbs8nqz835isi7sU+GE57/4+sX7jrZzYynpRyp53BM6TNHlEfFCqPGr1F68DxwEbRsSHkraKbpqzlsr3Q8gL2E8kLQ+MjIgzJP2XvFO/sqz+Tt3/jlc6zM1F7sMvJa0MPB0Rx5G5gmVjbHPVt8txersF6RDZvHIHYL+IuLmy7DcAEfHdiFhL0o3AmcAyEfFgX6elUaUl20LkfD/bAXNI+hvwEnkBukXSCxHxy4hYRlLLZtLrAO8C05bHg4AxwMflex0eESdL+oRszdaRohZNsvPoMpLuBu4li3RHRcRoSRuTRb8TpZWgK9vbKCLeIYuYxgD7lErjC4ETJS1UTpghwEKlnXuXJ0XpbHgUead1CPAlctKwDSVdTd4RLyVp0/K5H5f/HdOCqCelb8ZZwAcRcTIwAngI2ELSGcBbwPaSNoex+9ciU0S2EhsNvFZJ405k3dYwSSeUdHwJ+Gybg8jqwC+Ac4CfkXesJ5J3q6uQ/Q5GAUdK+iFARHTsRbQPvAGMkPTZyKkuJo8CWFHSWhFxakQ83eZ09kjSt8jc0xVkUdaaEfF4CSK7AocD34ps1txyDiRtorHDZrxKFtksCuwOnEc237tO0k+Ao4HfRcTori6QyvGR9gV2i4hLJU0dES8BfyPvPq8kW3AsCHyl1uy3v1AO63IE8NPa3X9EPBQRf4mILwP/R+7bTGSzzZaNlSRpPeAoSQuTd3vDK4sfiohVI2JVYFGN7dX+XKvS05NKa76ZgU8i4i3gr+RNy2zADBHxdbKF0j5kzvf8NiS1pepbNUbEVcBvyd9Xtbn4NmTjjMcmfip7V90P5fA/c5I3VLOTNwK/ljRZybm/CGwWEfdNrPS5aKsNSpO9T8rd4pIR8dtSzPVVsgz7t2QF8tTA5RFxSw+b+wD4CHivNDfdvzTxnQK4n7xITEZWrD/a4rv1PiVpMHlMDoyIqyTNSP6AFgHeiohrI+LHpY/Ig8BdtQtDC9KyAXlHf1hE/LfcvZ8q6eVyB3tzWW8T8mLd7jvaweR5MRMZTIiINyT9iWzhs5GkaSLiIuBSSVdGxJj2Jbc1KsVA3yRb8r1LtvQTcI2k68trawCbRMSTbUpqt1QZoaEUZ71YFl0PPBsRa5dlu5MlEZd1VwTeKg4kbRARUS5MvyTbfRMRl0t6kyxq2B84NSIamb/+DXIWyl8BnyPrSM4iK4L3AtaOiEuAi/p6P1qtFD0MBraSdA/wc/KiODMwlaRjI+KkiPiAbIjQEpVc3y4RcXspgnyUvJs/vPQ1eJqsw9kD2DIiXmlVehpI76zASGUnyZfI1noARMRbkk4lGyesL4kSTPrNDcb4Us7UujHZx+c3wKCIOEDSTWSgnRo4KiKeaF8qu1cJIquTxdY/IEeqWJYsCkc5PtpeZDCc6MMeOZC0Qanv2AX4ekQ8qBzyZC2yGOuvZFFUQz2xS1A6gWzSOw9wUbmwImk3stlvv1LtZEX2ofkecCPZNPNXwM1kU8elJ1KSarm+WifDA8j6hbcoZe5kjmhGYOt21okARMQrkr4D3EDWj9xZijzeJi+ir0q6oqxeKy7sF/VlE2hWstPtbsCbQC0Xe38p8utopTh6AbIP2MkR8bKkj8li8A0kbUa2VNwiIh5tSxon7fOnc9QujpJmihzA7zhgeXIogw/IIT6mj4g1Jc3a7B1tObkOAL4REf/X9A60gaRtgY3IgQQXj4gHKssOJIu4dmn1HVgpn/4e8BXG5vpuICv8NwVuiIi/S5qiFsQ7QWnJdyV5fp0PLEHePL5CFo/sNrEqYyeWupuQ2mvHk4H/EWDT8jvcDXgPOIOMox11IexmPzYj0/vViPhXqQ8Uee14OyLemPgpLaID2kVP6n+MDdgbksMxzE6eAAcDy5VlC5J3GFM2+VlzkPUiDwCfb/e+N7Ef3yCbzi5Y9/rkZCOCkWRwmVjpmZbs2LU52XKr9vopwPbV77mT/sihTt4i78oHkfUEs5HjkrU9fX28r9X+FRuTHUaXI0dxuBHYvyzbgbwJ6Mhe+5S+IeXxJsCPyFzv5OUa8hZltIpO+Wt7AgbKH9kh7B5gWOW1WoD5Glm5/rU++JypyN7xC7V7n5vcj/3I/jSrleeTkdn3bYE7OyFIkkPNjKwPdp32R3aevB+Yrd1pmUj7uy/ZS39fsuhuPWAlcvTsc8prHT8sEFl/ehdwKDmqxQnlhmBE+W2s0u401v5ctNVitRYXkg4ny9mPI+8q1iLL1w8lL5o3RMTFXWVpJ3XVfa4WD0k6hOyhu2VEPFAq3mcAJo+IF7vfYsvTOweZY9qVLDq8v11paZRyTptDyRxwv5+Dpqru/JmdbC6/eWk+vxQ5IGWU82cqsif7621McpdK8/I1I2Lf0qDj98AREfGYcsDPr5Nzi/xKOez/XRHxSDvTXON+JC1SafddG579WnLCoH+SRQvXltenAA4aqEEExmmi+T3gd5LOlzRLRBxGdtg8WdLSETEmIl5tZxAp3iBHZh7RH4IIQGTLrFUnwSDymcr5syY5iKYk/Y5sjLFFCSJbkONNje7QIPIVcoqIKwEi4j2ytd23yvNHyeLqL0kaFBFnd0oQAQeSlikn71fI4Tx2B4JsGrpBRBxBFmUNJ+tE+lVP81aQ9G1gA+D7wBfIvg2LRMTRZG/sYyQNqe9g1g4R8V5EXBYRHdl5rTsR0edDxrSTciKx48vjL5ONS64nO6muC+wZEe8pRx04gKxc7ziSvkSONLBHRFytnDJiXbJ7wNSl+TKMneqh44a2d/PfFpG0GtmxcGeybPMa8iIpScPJ0X2/298uRq1QWp/MTdZ/7ErWJb1ABpMREXF46TPyYTvTaZ2jBJGjgN1K/4ofASdGxMeSziVv3C6WdBVZZ7hFB+RkuzMlWe83l6THyIFJjyGHtb8M2E85wsN8ZPPyjmtp5zqSPlRp4juYDBojyYEXTyAr0p8p5euLk2Wd17cxuW1TV6Y9eUR8pLEDC54YOcwIkp4iK0a3jRb1WLf+p+T0LwCOjYj9JS0EXAzcHBE7l3WGkAFkNPB4RDzetgT3ovRp+SLw3fL/wIg4qbJ8crJV56sRMao9qeyZcyR9pBJE1iVbVjxOjsY7NbBRRDxX2oHPDPw5JsHhKBpVCSI7A/NLep68C3sNeLF00JyZHFL/Vw4iViNpbbLj7qHAcEm7RMRJpaL6Mkk/jIifltzrBe1Ma0+qN1Olccm/lOPvTcvY0b8/vdECHm5PShvjQNJHShBZnuygdgrZ6esNsrnhKOUgfoeQbdkHbBCpKUFkR7LPy3Xl5XPILP4u5PAPG0cHjn1k7VHu3BcgR7W9QdK9wEGSPokc/n0j4HxJU0bED9ub2u7V5ci3JUdEeIW8mQpgD0nTR8Qx/eUmyoGkjygHXfwlOUPhDeW184ElyTbtY4AfRI6pNSBbZ8GnrdmmJluw7UB28rsZOKkUcR1bVp26g8u0bSIrv5kPJJ0aOTfPZJEDeX4C/EA5ZtjJyqkSTpP0m4h4td3p7koliOwGbE9ORHUNOQLBZWQw+YGkDyLij21L6HhwHUkfkDR7RLwoaWlyKIoza3dEynG1piPPnxcGYhBRZfTSymvfJ0f2/Tgi1imvHQQ8HBEdWyRhE1/dHfw85Lw0L1eWr022yrogIo6tFAd1pHIzNRNZoX4g+TvYCli3VlqhHMH7iYh4tl3pHB9u/juBas1QJS1DDoq3d0TcTfY6XVPSjwFKu/XnI+KF8nxABREYZ/TSlSQtUxojPEDWgxxRlm1KdvJr64CH1lnqgsi+ZFPwk5RjrQEQEVeTo/quI2mGTgwi1WbrkV4DniBLMTYF1osc7fpHklaOiOv7SxABF21NsFInsg45Gc4VwM8lfRwRf5C0C3BWuRM/tK0JbaO6i8Ce5PD4N5JlwhuRzRl3LjmRqcjWWR3Tycrar3L+rEAOcroJMD1wiqQhEfGTst5lkv4VOXtlR6n7HSxPDtl/NznE/3bkMEAfSfo62Xv9rHaldUI5kEyAStb0UHKioyuUQ7lfXILH75Qzrk3X03YmZcpJk94pj79Mjpq7ckQ8X47VleQYSCcAnwXejDbO4WGdS9JyZL+rm6OMZK3sqX6mckbQAwE6MYjAOMFwL3K+obuALwMrknWFR5dc+uzkzVS/61vmoq0JUMma3gO8VoLHbeQd99GSNouIeyPixmqWdqCQtBiwtaQpJM1EziGyGGW4mIj4JjnEyB1kpfr/OYhYTf1vJiLuIHuwLyFpOUmDI+JhsgPrKpJm7cTfWTVNJSeyMTkT4+PA6MgREnYl60kOJecnmmjT4/YlB5IGVepE5pM0b3n5BXJWsinL8wfIoeB/XepOBmSdCJnT/RuZ05iCLP4bA6xXGh8QEd8ie+4ObVcirfPUFQNtKemg0lT8FOB04KfAMiWYPACsHhGvdNrvrBS71fZjJbKP1Jlko4B1yNHAa1MzPxUR90RjM6J2JLfaGg/KTk+/IJurLk4WzZxGXiRfAtYmy/53As6OiHvalNSJrr41mnJ+9Z+TfWl+TQ5U+XtyTKG/RsSbbUim9ROlGGgb8nxZEFiUHIttm/K3d0Tc2b4Udq/0Z1kuIg6RtCWZ3iPIYtx3ImL5st42ZF+qLaJDe6w3yoGkQZI+T54IW5Jlm78kJweqVbp/BriVnFjqD8D6EfFUu9I7sZU7xDG1/+W1lci5Vt4ng8hnyLvK48l+Iz75DADlMOmTl1wGkk4mh4O/uzz/GTBjROwpaT/yRu2ZtiW4G8rhW44kbyY/IousjoqI28qyM8ii3qHAmmSdSL8YQbonLtrqhqTZJc2jnOsa8s76ZGA1chytNUoQWSUiroyI08gZzI4l588YSEFkVuAxSTOXYFKrC7mF7FczNbAn8CpZzPUPBxGrkTQtmZt/odSpQV5o16qsdiFj69h+2aFB5Ktk8dX1EXEXecM5F7C5pOki4h9kq7PR5FTHm08KQQScI+lSqSw+i2znPSVZNPMQ2cx3MLBUaa73RbL4ZqeIeFzSlOS86y93s+lJlqQNyVzaypFz0n/aKUzSUuSovk8DR0cZNt+sViRabj4WAr5Jjpo9NXkTcmRE/Fk5lMj2lAtxp92IlPP/MOBysl7w/oj4S2nSuzrZsOTcWkvGSY2b/9aRtCg5mdLhwO1kncdXI+KfpZPhKcBW5c5pJ+CHUUYWjYj3yWKcASciLpE0BhgpaVgJJkMiB88bTLZwu9BBxGrq6tWmIOcL+ZCceuFUYAvgPGUv7+XIuoS32pHW7pRGOIPInPZeEXFTaZq8Ztm908oN5grAFMohXia5a4QDyf/aC5g5Is4HkPRv4IvKoRkuIu8uNgEEfK8EmAE37ElXSn+avRg3mOwF7E22runXFYrWd+paZ+0KLBY5xexpZD3kzmRd49LANGQDyJfald4eTFaKc6tTHVxBjpe1VtnN05UDTi5GBsxJLpC4aKsLki4ix4DaRNI3ycqzu4E5yXqS+yLisjYmsaMph9I/kryr3JWsM7q7nWmyzqGcKvbj8nh3crTnLWod8STNBnwHmIGccuGutiW2B3XBcP6ojFQtaXpylsbhwJ0R8SfliL4dlaPqK86RFNWTIiJGSLpE0l3k3cPC5LAGi5DjQV3VvpR2vpIzmYycT2SZgdQM2nomaUlglpLTn5JsvLIb8FYJKpuS42b9nrwJ6djxpipBZC9gB0mPkOm+JyLeknQFmQNZdlIOIuAcCTBOhd/6ZGehAyLi3ZLNHhoR61bW7eiRRTuJcviKjhy2wtqjVD7/h7yJfQnYnayPvAa4j5yXY2tyCJHB0YHTK6symrWkBchRfL9N7suMZBH4fyLni691wO246XH7kgNJIWkV4ERg14i4sfL6xWSz3o0cQMwmTN3Fdy7gOOD0iPibpJWBhyLiDUlrAvuRU1O/18Ykd6muOGtrSo4jIvYqrx0MzEO23rp6UqxY78qA7UdS+oh8sfLScOCsyPGxBinnSSYiNiJ7rn+hDck06/fKxbcWRJaLiOfIC+36kr5GNpV9Q9J3yWl09+/EIALjFGdtSk5ItQA5rty3yvKfk/2l1iRbcw0IA7KOpJTfLwU8Uym7fIU8KSBzah+VntkvRcSG7UqrWX9XufjuDXxFOc/6CZKCnL8nJN1Ajl23da13e6dSTqQ1AtghIm6VdDVwjHKWxj9GxA8lzTKp9hnpyoAMJOXu6NJSfnmOpF8D/wAukHQrcJukz5B9RrYhOyaa2QSStDo5Wu+6tWbgEXGicqrc7chc/zmd2Iy+UodaK9ZahBz/azVJD0fEf0qQPE3SRxFxUnToNL+tMqDqSCRNRfZKv6X0Xp+d7E07AvgBOQTDIcC75NAGR0XExe1Kr9mkQtI3yFkAty8lApPF2DHZNgduiA4c/bauTmRxcmiTN4ANgc3I0b6vjYi3S1H5CxEx4G48B1qOZCZgg1IWOx+wOTl0wcdkv4cfRMSGpdf6DBHxpDsbmo2fuovvlKXC+RGyTmSp0hz8kzLsyeQRcXI709uTyn7sQXaSfIQcmHV98sZzE7LH+uURcVPbEtpmAyqQRM7O9wKwD3BeRDwNIOkSsifq0ZJ+HRGXAK+X9ziImI2HysX3m8CCkkYB15JzcmymHNxwFLAvOTp0x1EOQPpaefxFsq/LCLJfy5HklNErkiNaDyd7sw9YAyKQVMo4ZwMuJYuuVpF0aEQcGhGvlA5SH5AVfmbWBEk7kPWLOwMjycYsRwOrAquQDVu2iIj/tiuN3ZE0H/AjSedFxFXkTeWtEfFUacb8/dLHbEREHCdppoh4u72pbq9Jvvlv+eJDOSnVzWTO4y/kUCeLSDpY0tLkMA1XR8TI9qXWrP+TNDXZXH4PYCXgFuCMyKHfz4qIPciJqTp5CPUHgI2VA0a+AqyhnEL7k7L8ZbKonIh4vU1p7BiTbGW7pGlrdwmSViBnMtw2Im6XNAPZSuTz5ICCKwN7RsTlbUuwWT8laWFgFnLo97sj4jVJ3yHnKP8wItYp6x0MPBcRf2lbYntQV7ezPfBVsh5kf3LcryvJjpSfkPu2ZUQ82p7UdpZJMkdSBkz7maRZykvTkrmQaUtF+03ksAavRsRWwFoOImbjrwwrdA45F/lBwL3K2UQfIkft/a2kIaUD3+bkLKIdqW7srF2B68lZDn8AvE0O2/I22Zt9GweRsSbJHImkacjgMRXwObKM9gTyjumv5Jg++wJ/i4gL25RMs35NOcX0oeTYdP8urx1CTkC1NjmHyLpkK6chZHHWfe1JbWOUw70fCxwXEXdKWogMgEuSk7Ld3tYEdqhJsrK99Ch9p1T47QzsFxEb1wYRLCfHEmSbcDMbT5JmJoc52Sgi/l1r5hsRh0kaBFxGXnyvJEf5HVNrBdVJ6pv3R8QHJf3flrRTRDwm6Xqyme82kh4E3nVrznFNqkVbK0taIiJOBf4E/FjSRiWIrEtmxX8SOae4mY2nEhQ2BH5RhgN5v9zNExE/Jkf2/UJEvBURL3d6EJG0hqSNy6IjyZZaB5fn05HzER0eEe84iPyvSSZHUmni+zmycmwxSZtETnUpYGflVLDXkyP83unOhmYTLiIuK0Oc3KaxM2LWpll4g2xO37Hq+rvsCXyonHv9WLJfyO6SrgNmJZsqv9KutHa6SSZHUoLI+uT4WFcDtwFnSvpCaSVyCdkRcXBE3Fl7T7vSazYpiIgryOmpR5b+FB9J2o4cfujl9qaud2UMsBHk0EnDyNac2wBPRcTXgR2A4R3eVLntJqnK9jL44m0RcbakIeRdxjbAVhHxiKR5Slt2M+tDpcj4KLJ57LbAbp1+8S2tOvcGdiRbYf1b0pRki85pgMOiTP9rPZtkciTFEOBLAJEzq10OvAX8UdJnHUTMWqPkTA4CfksWHXdcEClF3J+KHKH3GLKP2eaSVijjgn2X7IQ4oHurj49+myOp1IksS949vEK2wroSuCwifqKcT2RzshnwfyLirPal2GzSp34wvXLpJ7IQOcrFUcCHZC/82YAzB/LgixOq3+ZIKnUifyazpr9h7CBwm0g6Czi7LH+ZHBbezFqo04JIfS5EOW/IJuQQScOAC8hWWb8HRgNflzRl/fusZ/221ZZybpFvA/uUss3ZyYr2dclROeclB2dckAwum7UrrWbWNkMorceUE9nNQVau707eYD4E/I0MLkeSjXEGxDzrfalf5UhKR6GaT8gs6WiAiHiRrOj7fER8UEYVnZKs+Ns2Ih6Z2Ok1s/aR9BXgbEmHSPpaRIwGjiBvLkcAW5I5kWmBM4C33cR3wvSLQCJpAUkzRMTHkgZD9kAFbgdOKcPDAwwCFiqjjwI8CXw3ciIdMxsgyvAthwP/JK9z65cGN2+QTXwfIetO1wROJ/uJjGlTcvu9/lK0tSBwp6QFIuINSUMi4sOIOLw0871F0klkm+/vlB7sioiPccsLswGlMnzLiIi4RNLcwM+AocDjwFNkLuS3ZCBZOyKea1d6JwX9ptVWucM4Fqj1oJ2i5EooHaCeBd53iwszKw1xjgJWjoi3JF1ODtp6Lzm9du06MboUi1sT+kuOhIi4sjTbGylp+Rg7DeaqlNYXpQzUzAa4yvAtd0i6kqx0PxaYGfgO2d/s+xHxVhuTOcnoNzmSmtKD9tiI+GwZV+tfwDcj4oI2J83MOoyktYB/AHNExEvltcmAmV2x3nf6XSCBT4PJ+cCbwO4RcaEHYDSzrpTrxa+ANWrBxPpWvwwkkMM+AzNGxPkOImbWE0kjgEPIOtZPelvfxk+/DSQ1DiJm1ghJ00aEW3G2QL8PJGZm1l79okOimZl1LgcSMzNrigOJmZk1xYHEBgxJX5MUkhYrz+eX1GcTMEk6SdIS5fHBfbVds07nQGIDyZbADcAWfb1hSYMiYpeIeLC85EBiA4YDiQ0IkqYlh8XYmS4CiaSpJZ0r6V5J50i6VdKwsmxLSfdJul/SkZX3vC3pJ5JuBVaWdJ2kYZKOAKaSdLekM0rO5+GSY7m/vLaWpBsl/VfSCmV7M0u6sKThFklLltdXK9u6W9JdZV4Ns47hQGIDxcbAlRHxKPBamaK5ag/g9YhYkhx+fDkASXOSEx6tASwNLC9p4/KeaYD7I2LFiLihtqGIOBB4LyKWjoity8sLkaPNLgksBmwFrAJ8n7G5l8OAu0oaDibnEqess2dELA2sCrzX1JEw62MOJDZQbElOvUz5v2Xd8lVqyyPifnKUWIDlgesiYlSZr+IM4Mtl2cfA3xv8/Cci4r7Sq/oB4JrSkfY+YP5KGk4vabgWmEXSDMCNwK8lfYcczcHzZlhH6Tej/5pNKEmzkDmKz0sKcgK0IGfU/HS17t7ew6bfL3PeNOKDyuNPKs8/YezvsKvPiog4QtJlwHrk3DtrRcTDDX6uWcs5R2IDwabAaRExX0TMHxHzAE8Ac1fWuQHYHKC0vPpCef1WYDVJs5apnrcE/t3AZ34kafLxTOd/gK1LGoYDr5S5NBYsuZkjgZFk0ZhZx3AgsYFgS6B+moG/M27LquOAoZLuBQ4gi7bejIgXgIPI6QruAe6MiIsa+MwTgXslnTEe6TwUGFbScASwfXl9n1JJfw9ZP3LFeGzTrOU81pYZ2XwXmDwi3pe0IHANsEhEfNjmpJl1PNeRmKWpgX+V4igB33IQMWuMcyRmZtYU15GYmVlTHEjMzKwpDiRmZtYUBxIzM2uKA4mZmTXFgcTMzJry/6Mc6ple+wwUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Encontrar el valor máximo de exactitud\n",
    "max_accuracy = max(accuracy_scores.values())\n",
    "\n",
    "plt.bar(range(len(accuracy_scores)), list(accuracy_scores.values()), \n",
    "                                            align='center', \n",
    "                                            # Color elige que sea verde el valor máximo\n",
    "                                            color=['green' if v == max_accuracy else 'blue' for v in accuracy_scores.values()])\n",
    "plt.xticks(rotation=45) # Rotar las etiquetas en un ángulo de 45 grados\n",
    "plt.xticks(range(len(accuracy_scores)), list(accuracy_scores.keys()))\n",
    "plt.xlabel('Algoritmos')\n",
    "plt.ylabel('Exactitud')\n",
    "plt.title('Exactitud obtenida por diferentes algoritmos de clasificación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9c068-f97e-468e-9818-5fd79a8eb1d4",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63cad7f0-6d31-4555-8f6f-8066de03c870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.935933147632312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "dt_heart = pd.read_csv('./datasets/heart.csv')\n",
    "X = dt_heart.drop(['target'], axis=1)\n",
    "y = dt_heart['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=42)\n",
    "\n",
    "#Definimos nuestro clasificador\n",
    "#n_estimators: cuántos árboles vamos a usar para clasificar nuestro modelo\n",
    "\n",
    "# Lo que hace Boostin es construir árboles muy pequeños con muy poca profundidad\n",
    "# y pocas hojas y va intentar entrenarlos uno detrás de otro para lograr un resultado óptimo\n",
    "# que nos de la clasificación\n",
    "boost = GradientBoostingClassifier(n_estimators=50).fit(X_train, y_train)\n",
    "boost_pred = boost.predict(X_test)\n",
    "print('Accuracy score: ', accuracy_score(boost_pred, y_test)) # calculamos la metrica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af8d4d01-dbf9-4c65-b7e4-0e19487b3874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': 0.9916434540389972, 'n_estimator': 260}\n"
     ]
    }
   ],
   "source": [
    "# Para estimar el mejor n_estimators\n",
    "estimators = range(10, 300, 10)\n",
    "total_accuracy = []\n",
    "best_result = {'result' : 0, 'n_estimator': 1}\n",
    "\n",
    "for i in estimators:\n",
    "    boost = GradientBoostingClassifier(n_estimators=i).fit(X_train, y_train)\n",
    "    boost_pred = boost.predict(X_test)\n",
    "    new_accuracy = accuracy_score(boost_pred, y_test)\n",
    "    total_accuracy.append(new_accuracy)\n",
    "    if new_accuracy > best_result['result']: \n",
    "        best_result['result'] = new_accuracy\n",
    "        best_result['n_estimator'] = i\n",
    "\n",
    "print(best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18f3be-c52e-49a6-9233-36bc6a537641",
   "metadata": {},
   "source": [
    "## Estrategias de clustering\n",
    "\n",
    "Son estrategias de aprendizaje no suprvisado para agrupar los datos de manera que todos los datos pertenecientes a un grupo sean lo mas similares entre sí y los mas lejanos los mas diferentes entre sí.\n",
    "\n",
    "Dos escenarios de aplicación:\n",
    "\n",
    "* Cuando sabemos la cantidad de grupos que queremos\n",
    "* Cuando no sabemos la cantidad de grupos que queremos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f055838a-a68a-417d-81c7-7a58a4f00728",
   "metadata": {},
   "source": [
    "### Cuando sabemos la cantidad de \"k\" con las que agrupar\n",
    "Supangamos que trabajamos en una tienda de caramelos y queremos organizar todos los caramelos en 4 estantes, donde cada estante tenga caramelos con caracteristicas similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cf5208b-dd1a-4872-a2ed-9237d7059713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans #Igual que Kmean pero consume menos recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90ab0fa6-0a3c-43cb-910f-9255f49f2207",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  \n",
       "0   66.971725  \n",
       "1   67.602936  \n",
       "2   32.261086  \n",
       "3   46.116505  \n",
       "4   52.341465  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./datasets/candy.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4b617cf3-b23b-418a-9156-fdf44c93164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# como es un algoritmo no supervisado no tenemos que partir en train/test\n",
    "# vamos a usar todos los datos juntos\n",
    "\n",
    "# Guardamos en una variable todos los datos menos la columna con el nombre del caramelo\n",
    "X = dataset.drop('competitorname', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea7a9d1b-5c77-46b3-b5d7-323785147632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de centros:  4\n",
      "Etiquetas:  [1 1 2 0 3 0 3 2 2 2 2 2 2 0 2 0 2 0 3 2 3 0 3 3 3 3 2 3 1 0 2 3 1 1 0 3 1\n",
      " 3 1 0 3 3 1 1 2 2 0 1 2 0 2 1 1 1 1 2 1 2 0 2 3 3 2 0 1 3 3 3 1 2 2 2 2 3\n",
      " 0 0 0 0 0 1 0 2 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Guardamos nuestro modelo en una variable y configuramos\n",
    "# n_clusters= me dice la cantidad de cluster que yo quiero\n",
    "# batch_size= definimos la cantiad de datos que van a ir pasando por el algoritmo por cada batch\n",
    "kmeans = MiniBatchKMeans(n_clusters=4, batch_size=8).fit(X)\n",
    "\n",
    "#Es un valor que devuelve automáticamente el modelo donde nos dice la cantidad de cluster que va a usar\n",
    "print('Total de centros: ', len(kmeans.cluster_centers_)) \n",
    "# Vamos a ver con qué etiqueta va a imprimir cada grupo\n",
    "# Me devuelve un arreglo con la etiqueta que le dio a cada caramelo en orden como estan en el dataset\n",
    "print('Etiquetas: ', kmeans.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9755352-29fc-44dd-985c-5014c24354b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#El arreglo de etiquetas así como esta no es muy útil\n",
    "# Lo que podemos hacer es pegar ese arreglo al conjunto de datos original\n",
    "\n",
    "#Creamos una nueva columna en el conjunto de datos original\n",
    "# y le decimos los datos que queremos pegar, en este caso las predicciones\n",
    "dataset['group'] = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6109d3cb-57ca-4b56-842f-571a44e508b5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  group  \n",
       "0   66.971725      1  \n",
       "1   67.602936      1  \n",
       "2   32.261086      2  \n",
       "3   46.116505      0  \n",
       "4   52.341465      3  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5397202e-dd63-4704-a69a-5c684c8cef9a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seabornNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
      "     ------------------------------------ 293.3/293.3 kB 533.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\marco\\.conda\\envs\\mlenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.12.2\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 23.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01284b06-4507-49aa-b39d-5b94a7085626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='sugarpercent', ylabel='winpercent'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot(data=dataset, \n",
    "                x=\"sugarpercent\", \n",
    "                y=\"winpercent\", \n",
    "                hue=\"group\",\n",
    "                palette=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5157f3c-8331-4ff4-8056-90101836883c",
   "metadata": {},
   "source": [
    "### Cuando queremos que el algoritmo decida la cantidad de \"k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88ddefa1-d8d0-4a19-9994-9bc53492d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meanshift sirve para una cantidad moderada de datos\n",
    "from sklearn.cluster import MeanShift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb0f6b70-e8a8-4898-9cc5-dfa994a1b8c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  \n",
       "0   66.971725  \n",
       "1   67.602936  \n",
       "2   32.261086  \n",
       "3   46.116505  \n",
       "4   52.341465  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./datasets/candy.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e874fb52-3fd9-46ca-881c-db9d4c8ae3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas:  [2 2 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 2 1 2 0 1 2 0 0 1 2 2 0 1 2\n",
      " 2 2 1 1 1 2 2 0 0 0 2 0 0 0 2 2 2 2 0 2 0 0 0 2 1 0 0 2 2 2 1 2 0 0 0 0 1\n",
      " 1 0 0 1 1 2 0 0 0 0 1]\n",
      "Mayor valor de etiqueta:  2\n"
     ]
    }
   ],
   "source": [
    "X = dataset.drop('competitorname', axis=1)\n",
    "\n",
    "# Hacemos una variable para guardar el modelo\n",
    "# Para configurarlo, por defecto él usa una ecuación matemática para el ancho de banda\n",
    "\n",
    "meanshift = MeanShift().fit(X)\n",
    "print('Etiquetas: ', meanshift.labels_) #Me muestra el arreglo de etiquetas\n",
    "print('Mayor valor de etiqueta: ', max(meanshift.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a7d48-a3d5-41ea-bd0c-1140b1be7afa",
   "metadata": {},
   "source": [
    "Como las etiquetas empiezan de cero, entonces podemos ver que son 3 grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01962c07-6ef5-4598-a1e6-0f01d3a68dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ubicación de los centros:  [[2.25000000e-01 5.75000000e-01 1.00000000e-01 2.50000000e-02\n",
      "  5.00000000e-02 2.50000000e-02 3.00000000e-01 1.00000000e-01\n",
      "  5.50000000e-01 4.57599993e-01 3.67824996e-01 4.10442122e+01]\n",
      " [4.68750000e-01 5.00000000e-01 1.25000000e-01 1.56250000e-01\n",
      "  9.37500000e-02 6.25000000e-02 1.25000000e-01 3.12500000e-01\n",
      "  5.31250000e-01 4.57281243e-01 4.67874998e-01 5.21138597e+01]\n",
      " [8.26086957e-01 1.73913043e-01 3.04347826e-01 3.04347826e-01\n",
      "  1.73913043e-01 1.73913043e-01 0.00000000e+00 5.21739130e-01\n",
      "  4.34782609e-01 5.81391293e-01 6.38086963e-01 6.47120799e+01]]\n"
     ]
    }
   ],
   "source": [
    "# La ubicación de los centros que puso sobre los datos\n",
    "print('Ubicación de los centros: ', meanshift.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b97672d3-d769-4a1e-84ad-22eac10e71ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>competitorname</th>\n",
       "      <th>chocolate</th>\n",
       "      <th>fruity</th>\n",
       "      <th>caramel</th>\n",
       "      <th>peanutyalmondy</th>\n",
       "      <th>nougat</th>\n",
       "      <th>crispedricewafer</th>\n",
       "      <th>hard</th>\n",
       "      <th>bar</th>\n",
       "      <th>pluribus</th>\n",
       "      <th>sugarpercent</th>\n",
       "      <th>pricepercent</th>\n",
       "      <th>winpercent</th>\n",
       "      <th>meanshift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 Grand</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.860</td>\n",
       "      <td>66.971725</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3 Musketeers</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.511</td>\n",
       "      <td>67.602936</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One dime</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.116</td>\n",
       "      <td>32.261086</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>One quarter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.511</td>\n",
       "      <td>46.116505</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Air Heads</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.511</td>\n",
       "      <td>52.341465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  competitorname  chocolate  fruity  caramel  peanutyalmondy  nougat  \\\n",
       "0      100 Grand          1       0        1               0       0   \n",
       "1   3 Musketeers          1       0        0               0       1   \n",
       "2       One dime          0       0        0               0       0   \n",
       "3    One quarter          0       0        0               0       0   \n",
       "4      Air Heads          0       1        0               0       0   \n",
       "\n",
       "   crispedricewafer  hard  bar  pluribus  sugarpercent  pricepercent  \\\n",
       "0                 1     0    1         0         0.732         0.860   \n",
       "1                 0     0    1         0         0.604         0.511   \n",
       "2                 0     0    0         0         0.011         0.116   \n",
       "3                 0     0    0         0         0.011         0.511   \n",
       "4                 0     0    0         0         0.906         0.511   \n",
       "\n",
       "   winpercent  meanshift  \n",
       "0   66.971725          2  \n",
       "1   67.602936          2  \n",
       "2   32.261086          0  \n",
       "3   46.116505          0  \n",
       "4   52.341465          1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# también podemos integrar los grupos que predijo a nuestro conjunto de datos originales\n",
    "dataset['meanshift'] = meanshift.labels_\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e206e7a1-e016-46c5-b15c-8f178ac6c45a",
   "metadata": {},
   "source": [
    "## Validación de datos por K-Fols\n",
    "\n",
    "Hay varios métodos de validación:\n",
    "\n",
    "* **Hold Out**: lo que hacemos normalmente, cuando dividimos los datos en entrenamiento/prueba.\n",
    "* **K-fold**: cuando plegamos nuestros datos k veces y usamos estas configuraciones cada vez en el entrenamiento, intentando cubrir todos los datos de entrenamiento y testeo al finalizar el proceso.\n",
    "* **LOOCV**: Leave One Out Cross Validation. Este es un método mas intensivo, donde se hacen particiones entre entrenamiento y pruebas, con todos los datos para el entrenamiento excepto un valor, que se usa para la prueba. Se repite este proceso tantas veces hasta que se usen todos los datos para la prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1803ec3a-6cda-4d7c-9408-b34073f0bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Traemos un árbol de decisión para predecir el valor de una variable continua\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import (cross_val_score, KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0989ab76-9aea-411c-884b-8bb63f0a2c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>gdp</th>\n",
       "      <th>family</th>\n",
       "      <th>lifexp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption</th>\n",
       "      <th>dystopia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norway</td>\n",
       "      <td>1</td>\n",
       "      <td>7.537</td>\n",
       "      <td>7.594445</td>\n",
       "      <td>7.479556</td>\n",
       "      <td>1.616463</td>\n",
       "      <td>1.533524</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.635423</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.315964</td>\n",
       "      <td>2.277027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>7.522</td>\n",
       "      <td>7.581728</td>\n",
       "      <td>7.462272</td>\n",
       "      <td>1.482383</td>\n",
       "      <td>1.551122</td>\n",
       "      <td>0.792566</td>\n",
       "      <td>0.626007</td>\n",
       "      <td>0.355280</td>\n",
       "      <td>0.400770</td>\n",
       "      <td>2.313707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>3</td>\n",
       "      <td>7.504</td>\n",
       "      <td>7.622030</td>\n",
       "      <td>7.385970</td>\n",
       "      <td>1.480633</td>\n",
       "      <td>1.610574</td>\n",
       "      <td>0.833552</td>\n",
       "      <td>0.627163</td>\n",
       "      <td>0.475540</td>\n",
       "      <td>0.153527</td>\n",
       "      <td>2.322715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>4</td>\n",
       "      <td>7.494</td>\n",
       "      <td>7.561772</td>\n",
       "      <td>7.426227</td>\n",
       "      <td>1.564980</td>\n",
       "      <td>1.516912</td>\n",
       "      <td>0.858131</td>\n",
       "      <td>0.620071</td>\n",
       "      <td>0.290549</td>\n",
       "      <td>0.367007</td>\n",
       "      <td>2.276716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5</td>\n",
       "      <td>7.469</td>\n",
       "      <td>7.527542</td>\n",
       "      <td>7.410458</td>\n",
       "      <td>1.443572</td>\n",
       "      <td>1.540247</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.617951</td>\n",
       "      <td>0.245483</td>\n",
       "      <td>0.382612</td>\n",
       "      <td>2.430182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  rank  score      high       low       gdp    family    lifexp  \\\n",
       "0       Norway     1  7.537  7.594445  7.479556  1.616463  1.533524  0.796667   \n",
       "1      Denmark     2  7.522  7.581728  7.462272  1.482383  1.551122  0.792566   \n",
       "2      Iceland     3  7.504  7.622030  7.385970  1.480633  1.610574  0.833552   \n",
       "3  Switzerland     4  7.494  7.561772  7.426227  1.564980  1.516912  0.858131   \n",
       "4      Finland     5  7.469  7.527542  7.410458  1.443572  1.540247  0.809158   \n",
       "\n",
       "    freedom  generosity  corruption  dystopia  \n",
       "0  0.635423    0.362012    0.315964  2.277027  \n",
       "1  0.626007    0.355280    0.400770  2.313707  \n",
       "2  0.627163    0.475540    0.153527  2.322715  \n",
       "3  0.620071    0.290549    0.367007  2.276716  \n",
       "4  0.617951    0.245483    0.382612  2.430182  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./datasets/felicidad.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56e7d32-b0bc-45ed-80b3-30d4f2c67d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos nuestro conjunto de datos sin las columnas del pais y puntaje\n",
    "# ajustamos al eje de las columnas\n",
    "X = dataset.drop(['country', 'score'], axis=1)\n",
    "# La columna que vamos a predecir es score\n",
    "y = dataset['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081f530a-4791-49d0-9359-7fd5f5dce586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora usamos nuestro modelo, y lo dejamos con la configuración por defecto\n",
    "model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "019ea258-7931-4edd-a094-cc457648a444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  [-0.84230062 -0.15857899 -0.72276584]\n"
     ]
    }
   ],
   "source": [
    "# Antes en este punto usabamos fit para ajustar a nuestros datos\n",
    "# Pero ahora, como vamos a usar Cross Validation, y CV se encarga de todo el proceso\n",
    "# entonces vamos a llamar directamente a la función de cross validation\n",
    "# esto es recomendable para cuando queremos hacer una prueba rápida con las configuraciones por defecto\n",
    "\n",
    "score = cross_val_score(model, #mandamos nuestro modelo\n",
    "                       X, #mandamos los features\n",
    "                       y, #mandamos los target\n",
    "                       cv=3,\n",
    "                       scoring='neg_mean_squared_error',) #opcional: podemos elegir el método con el que vamos a hacer CV\n",
    "print('Score: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27225491-f3ae-4353-8e24-15aaa70b9d33",
   "metadata": {},
   "source": [
    "Nos da un arreglo de todos valores negativos. Son negativos por el scorig elegido.\n",
    "\n",
    "Cada uno de los valores dentro del arreglo es el error medio cuadrático que obtuvo de cada una de las pruebas.\n",
    "\n",
    "Por defecto el CV hace 5 pliegues de los datos. Esto se puede configurar con cv= indicando la cantidad de pliegues que quiero.\n",
    "\n",
    "Para trabajar con estos arreglos que son negativos y son varios valores es que usamos numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "affcc97a-06aa-4582-9780-6468618f4d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio de los score de CV:  -0.5745484826672641\n",
      "Valor absoluto de ese promedio:  0.5745484826672641\n"
     ]
    }
   ],
   "source": [
    "print('Promedio de los score de CV: ', np.mean(score))\n",
    "print('Valor absoluto de ese promedio: ', np.abs(np.mean(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51701a2e-d50d-4ab7-a67a-223bae444f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  [  0   1   2   3   4   5   6   7   8  10  13  14  16  17  20  21  23  25\n",
      "  28  32  33  34  35  37  38  39  40  41  43  44  46  47  48  49  50  52\n",
      "  53  54  57  58  59  61  62  63  64  67  70  71  72  73  74  77  80  83\n",
      "  87  88  89  91  92  94  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 110 111 112 113 114 115 116 120 121 123 125 127 128 129 130 132 134 135\n",
      " 136 139 140 143 144 145 146 148 149 150 151 152 154]\n",
      "Test:  [  9  11  12  15  18  19  22  24  26  27  29  30  31  36  42  45  51  55\n",
      "  56  60  65  66  68  69  75  76  78  79  81  82  84  85  86  90  93  95\n",
      "  96 109 117 118 119 122 124 126 131 133 137 138 141 142 147 153]\n",
      "====================================================================================================\n",
      "Train:  [  1   2   3   6   8   9  11  12  13  14  15  17  18  19  20  21  22  24\n",
      "  26  27  29  30  31  36  37  38  42  45  48  50  51  52  54  55  56  57\n",
      "  58  59  60  63  65  66  68  69  71  72  74  75  76  78  79  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  95  96  99 100 102 103 106 107\n",
      " 109 112 115 116 117 118 119 120 121 122 124 126 128 129 130 131 132 133\n",
      " 135 137 138 139 140 141 142 145 147 149 152 153 154]\n",
      "Test:  [  0   4   5   7  10  16  23  25  28  32  33  34  35  39  40  41  43  44\n",
      "  46  47  49  53  61  62  64  67  70  73  77  80  94  97  98 101 104 105\n",
      " 108 110 111 113 114 123 125 127 134 136 143 144 146 148 150 151]\n",
      "====================================================================================================\n",
      "Train:  [  0   4   5   7   9  10  11  12  15  16  18  19  22  23  24  25  26  27\n",
      "  28  29  30  31  32  33  34  35  36  39  40  41  42  43  44  45  46  47\n",
      "  49  51  53  55  56  60  61  62  64  65  66  67  68  69  70  73  75  76\n",
      "  77  78  79  80  81  82  84  85  86  90  93  94  95  96  97  98 101 104\n",
      " 105 108 109 110 111 113 114 117 118 119 122 123 124 125 126 127 131 133\n",
      " 134 136 137 138 141 142 143 144 146 147 148 150 151 153]\n",
      "Test:  [  1   2   3   6   8  13  14  17  20  21  37  38  48  50  52  54  57  58\n",
      "  59  63  71  72  74  83  87  88  89  91  92  99 100 102 103 106 107 112\n",
      " 115 116 120 121 128 129 130 132 135 139 140 145 149 152 154]\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Si queremos saber como funciona CV de fondo tenemos que usar la función K-fold\n",
    "kf = KFold(n_splits=3, #es el número de pliegues que queremos\n",
    "          shuffle=True, #Si queremos que se organicen en forma aleatoria o en el orden del conjunto de datos\n",
    "          random_state=42) #para mantener la replicabilidad\n",
    "#Esto lo pasamos por un for para que por cada partición nos muestre los elementos de train y test\n",
    "for train, test in kf.split(dataset):\n",
    "    print('Train: ', train) #Me muestra los elementos que elige para entrenamiento\n",
    "    print('Test: ', test) #Me muestra los elementos que elige para testeo\n",
    "    print('='*100)\n",
    "\n",
    "# Luego aca podemos pasar train y test por el modelo que querramos como hicimos antes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe02d2-4734-4175-92ae-d96c37389383",
   "metadata": {},
   "source": [
    "Cada arreglo contiene los índices de la partición que hizo en cada pliegue.\n",
    "\n",
    "El primer arrgle es el conjunto de train y el segundo arreglo es el conjunto de test, para cada pliegue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de524e-21f5-42f4-99de-aca2fb2f49dc",
   "metadata": {},
   "source": [
    "## Optimización paramétrica con CV\n",
    "Para lograr automatizar un poco este proceso de ML, es decir, la selección y la optimización del modelo, teniendo en cuenta cómo funciona el proceso de Cros Validation. Una vez que encontramos el modelo que parece funcionar, necesitamos encontrar  la optimización de cada uno de los parámetros para encontrar el que mejor se ajuste y el que mejor resultado nos de.\n",
    "\n",
    "La optimización paramétrica es una labor bastante tediosa, hay muchos parámetros que se pueden optimizar y es fácil perderse entre los conceptos de tantos parámetros que nos ofrece Scikit-learn. Es dififícil medir la sensibiliad de los mismos si lo hacemos manualmente y aunque lo hicieramos dentro de un ciclo for, esto sería muy costoso computacionalmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c6f149-c87f-444e-927c-b53c7491d004",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5add3bc7-fa47-414e-b646-825e9cfc7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eefd9040-f7d5-4faa-a1c1-bf51633d6b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./datasets/felicidad.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49cbf7e9-1008-41b9-ad0e-6aba7ae4efd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>gdp</th>\n",
       "      <th>family</th>\n",
       "      <th>lifexp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption</th>\n",
       "      <th>dystopia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norway</td>\n",
       "      <td>1</td>\n",
       "      <td>7.537</td>\n",
       "      <td>7.594445</td>\n",
       "      <td>7.479556</td>\n",
       "      <td>1.616463</td>\n",
       "      <td>1.533524</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.635423</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.315964</td>\n",
       "      <td>2.277027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>2</td>\n",
       "      <td>7.522</td>\n",
       "      <td>7.581728</td>\n",
       "      <td>7.462272</td>\n",
       "      <td>1.482383</td>\n",
       "      <td>1.551122</td>\n",
       "      <td>0.792566</td>\n",
       "      <td>0.626007</td>\n",
       "      <td>0.355280</td>\n",
       "      <td>0.400770</td>\n",
       "      <td>2.313707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iceland</td>\n",
       "      <td>3</td>\n",
       "      <td>7.504</td>\n",
       "      <td>7.622030</td>\n",
       "      <td>7.385970</td>\n",
       "      <td>1.480633</td>\n",
       "      <td>1.610574</td>\n",
       "      <td>0.833552</td>\n",
       "      <td>0.627163</td>\n",
       "      <td>0.475540</td>\n",
       "      <td>0.153527</td>\n",
       "      <td>2.322715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>4</td>\n",
       "      <td>7.494</td>\n",
       "      <td>7.561772</td>\n",
       "      <td>7.426227</td>\n",
       "      <td>1.564980</td>\n",
       "      <td>1.516912</td>\n",
       "      <td>0.858131</td>\n",
       "      <td>0.620071</td>\n",
       "      <td>0.290549</td>\n",
       "      <td>0.367007</td>\n",
       "      <td>2.276716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5</td>\n",
       "      <td>7.469</td>\n",
       "      <td>7.527542</td>\n",
       "      <td>7.410458</td>\n",
       "      <td>1.443572</td>\n",
       "      <td>1.540247</td>\n",
       "      <td>0.809158</td>\n",
       "      <td>0.617951</td>\n",
       "      <td>0.245483</td>\n",
       "      <td>0.382612</td>\n",
       "      <td>2.430182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       country  rank  score      high       low       gdp    family    lifexp  \\\n",
       "0       Norway     1  7.537  7.594445  7.479556  1.616463  1.533524  0.796667   \n",
       "1      Denmark     2  7.522  7.581728  7.462272  1.482383  1.551122  0.792566   \n",
       "2      Iceland     3  7.504  7.622030  7.385970  1.480633  1.610574  0.833552   \n",
       "3  Switzerland     4  7.494  7.561772  7.426227  1.564980  1.516912  0.858131   \n",
       "4      Finland     5  7.469  7.527542  7.410458  1.443572  1.540247  0.809158   \n",
       "\n",
       "    freedom  generosity  corruption  dystopia  \n",
       "0  0.635423    0.362012    0.315964  2.277027  \n",
       "1  0.626007    0.355280    0.400770  2.313707  \n",
       "2  0.627163    0.475540    0.153527  2.322715  \n",
       "3  0.620071    0.290549    0.367007  2.276716  \n",
       "4  0.617951    0.245483    0.382612  2.430182  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e482adb-ad70-4aab-ae5e-04a9036bb2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(['country', 'rank', 'score'], axis=1)\n",
    "y = dataset['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7785e682-cac5-43db-9ddf-a124a7cc8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definismo el regresor que vamos a usar y lo dejamos sin parámetros\n",
    "reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "531e248f-0c7c-4330-ab22-79842c7de42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a definir la grilla de parámetros que va a utilizar \n",
    "# nuestro optimizador para que nos busque la mejor combinación de parámetros\n",
    "# Esta grilla es un diccionario\n",
    "parametros = {\n",
    "    'n_estimators' : range(4,16), # Cuántos árboles van a componer mi bosque, entre 4 y 15 (pongo 16 porque es n-1)\n",
    "    'criterion'    : ['absolute_error', 'squared_error'], #Es una medida de calidad de los split que hace mi árbol. Me dice que tan bueno o malo fue\n",
    "    'max_depth'    : range(2,10) #Para limitar qué tan profundo queremos nuestros árboles\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "73c8d228-a2b3-4a0c-aa40-6bb26f5f802f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mejor combinación de estimadores:\n",
      "RandomForestRegressor(criterion='absolute_error', max_depth=8, n_estimators=13)\n",
      "  Mejores parámetros encontrados:\n",
      "{'n_estimators': 13, 'max_depth': 8, 'criterion': 'absolute_error'}\n",
      "  Mejor scoring:\n",
      "0.5874133422674036\n"
     ]
    }
   ],
   "source": [
    "# Vamos a definir nuestro optimizador\n",
    "rand_est = RandomizedSearchCV(reg, #Le decimos cual es nuestro modelo\n",
    "                              parametros, #Le decimos cuales son los parámetros de la grilla\n",
    "                              n_iter=10, #Le limitamos la cantidad de iteraciones o configuraciones de cada uno de los parámtros definidos en parametros\n",
    "                              cv=3, #Como vamos a usar CV le decimos los pliegues que queremos\n",
    "                              scoring='neg_mean_squared_error').fit(X, y) #Le decimos con que función queremos medir que tan bien nos fue\n",
    "                                                                          #Y entrenamos\n",
    "print('  Mejor combinación de estimadores:')\n",
    "print(rand_est.best_estimator_)\n",
    "print('  Mejores parámetros encontrados:')\n",
    "print(rand_est.best_params_)\n",
    "print('  Mejor scoring:')\n",
    "print(np.abs(rand_est.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "478ff9eb-b24a-49c6-8c71-b3f4b1c7d252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7.5273078]\n"
     ]
    }
   ],
   "source": [
    "# Hacemos una predicción muy simple\n",
    "# Cuando le pedimos una predicción, automáticamente va a tomar el best_estimator_ para hacerla\n",
    "print(rand_est.predict(X.loc[[0]])) #Queremos ver que predice para la primer fila, es decir, el score para el primer país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd8f11cd-1e21-497b-85d2-d66afb34e62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>gdp</th>\n",
       "      <th>family</th>\n",
       "      <th>lifexp</th>\n",
       "      <th>freedom</th>\n",
       "      <th>generosity</th>\n",
       "      <th>corruption</th>\n",
       "      <th>dystopia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Norway</td>\n",
       "      <td>1</td>\n",
       "      <td>7.537</td>\n",
       "      <td>7.594445</td>\n",
       "      <td>7.479556</td>\n",
       "      <td>1.616463</td>\n",
       "      <td>1.533524</td>\n",
       "      <td>0.796667</td>\n",
       "      <td>0.635423</td>\n",
       "      <td>0.362012</td>\n",
       "      <td>0.315964</td>\n",
       "      <td>2.277027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  rank  score      high       low       gdp    family    lifexp  \\\n",
       "0  Norway     1  7.537  7.594445  7.479556  1.616463  1.533524  0.796667   \n",
       "\n",
       "    freedom  generosity  corruption  dystopia  \n",
       "0  0.635423    0.362012    0.315964  2.277027  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vemos que la etiqueta real era de 7.537\n",
    "dataset.loc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a70f1-f603-4053-91fc-cc96201b1084",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "47ec0536-9e3c-4a13-aa51-e1d55943bb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e5c8d990-08d5-455c-8a51-20b66b08f1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defino de los modelos a usar\n",
    "reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "093bc9a0-06f4-4503-a067-9c52d551ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino los parámetos que quiero iterar\n",
    "params = {'n_estimators' : range(4,16),\n",
    "          'criterion'    : ['absolute_error', 'squared_error'],\n",
    "          'max_depth'    : range(2,10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b4fda11-f70d-43e7-aaf5-60bb03689a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_reg = GridSearchCV(reg,\n",
    "                        params,\n",
    "                        cv=3,\n",
    "                        scoring='neg_mean_squared_error').fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d49018bd-5c75-4f47-a8df-499fcfc98bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Mejor combinación de estimadores:\n",
      "RandomForestRegressor(criterion='absolute_error', max_depth=5, n_estimators=4)\n",
      "  Mejores parámetros encontrados:\n",
      "{'criterion': 'absolute_error', 'max_depth': 5, 'n_estimators': 4}\n",
      "  Mejor scoring:\n",
      "0.568968139874565\n"
     ]
    }
   ],
   "source": [
    "print('  Mejor combinación de estimadores:')\n",
    "print(grid_reg.best_estimator_)\n",
    "print('  Mejores parámetros encontrados:')\n",
    "print(grid_reg.best_params_)\n",
    "print('  Mejor scoring:')\n",
    "print(np.abs(grid_reg.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677f2781-2dcd-4f4a-b89e-1e2c30602096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mlenv]",
   "language": "python",
   "name": "conda-env-.conda-mlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
